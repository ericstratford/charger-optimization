{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c38abf-1031-4f3f-898e-c2adfd8f95a0",
   "metadata": {},
   "source": [
    "# Public EV Charger Placement Optimization Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb6006e-7747-4f51-bce8-572a99a15ec5",
   "metadata": {},
   "source": [
    "## EVCS-OPTIM\n",
    "Electric Vehicle Charging Station - Optimization Placement Tool via Intersection Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a857276f-ce41-4b76-9c1e-64683c0a59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import branca\n",
    "\n",
    "import osmnx as ox\n",
    "from geopy.distance import geodesic\n",
    "from shapely.geometry import Point, Polygon, mapping, MultiPolygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce14316-8af9-46d4-807e-8746f6f30996",
   "metadata": {},
   "source": [
    "**Brainstorm**\n",
    "\n",
    "Top Charging Locations by Type:\n",
    "- Shopping Centers\n",
    "- Other commercial destinations\n",
    "- Offices (Semi-Private)\n",
    "- Parks\n",
    "- Libraries\n",
    "- Schools\n",
    "- Other public spaces\n",
    "- Hospitals/Clinics\n",
    "- Public Transit Stations\n",
    "- Rest/Refuel Stations\n",
    "- High Density Residential/Mixed\n",
    "- Community Centers / Churches\n",
    "- Stadiums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2530286c-be97-48f5-9715-cbc53c1592d3",
   "metadata": {},
   "source": [
    "**Consumer Costs**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d45f36b-483d-4639-a515-d8e2daa8630e",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a2d885-13c3-4d6d-8219-6e034a9be63e",
   "metadata": {},
   "source": [
    "### Charger Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a04b64-c248-4ca2-b96f-2e0cf321fed7",
   "metadata": {},
   "source": [
    "Let's start our data gathering process by collecting information on public EV chargers in California through AFDC database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f58a4e-103f-4834-a03a-218ac047a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger Data Query\n",
    "url = \"https://developer.nrel.gov/api/alt-fuel-stations/v1.json\"\n",
    "params = {\n",
    "    'format': 'json',  # Output response format\n",
    "    'api_key': 'Tbqhfv28h6gIIxbaMTByUNg4ByP2vf1E1A3XYgGa',  # Your developer API key\n",
    "    'status': 'all',  # Return stations that match the given status\n",
    "    # 'access': 'public',  # Return stations with the given access type\n",
    "    'fuel_type': 'ELEC', # Return stations that supply any of the given fuel types\n",
    "    'state': 'CA',\n",
    "    'country': 'US',\n",
    "    \n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "if response.status_code == 200:\n",
    "\n",
    "    data = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8dd59-6006-456f-834e-a1a34aee981d",
   "metadata": {},
   "source": [
    "### SDG&E Territory Zip Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c511ac91-429f-4837-b018-f54b22e177c4",
   "metadata": {},
   "source": [
    "We will need to use SDG&E territory zip codes to filter much of our data by the relevant geographical area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdae4be-7b4b-4b2f-86b8-639be3ea4d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdge_zips_data = pd.read_excel(\"data/SDGE Service Territory Zip Code List Q2-2021.xlsx\")\n",
    "sdge_zips = list(sdge_zips_data['ZIP_CODE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85333b8d-a69b-4c9d-a23c-668e73d71734",
   "metadata": {},
   "source": [
    "### Zoning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eafe6f-42bf-4ecd-af99-7042d1ed0429",
   "metadata": {},
   "source": [
    "Zoning regulations and land-use can be a useful determinant of where EV chargers might be located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3906bdfc-d2bc-4907-84bd-5696f0e7f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoning_data = gpd.read_file(\"shapefiles/zoning_datasd.geojson\")\n",
    "\n",
    "zoning_data = zoning_data.to_crs(epsg=4326)  # Convert to WGS84 (EPSG:4326)\n",
    "\n",
    "# Convert zone codes to types\n",
    "zoning_categories = {\n",
    "    'Commercial': ['CC', 'CN', 'CV', 'CP', 'CR', 'CCPD'],\n",
    "    'Office': ['CO'],\n",
    "    'Residential High': ['RH', 'RM-3', 'RM-4'],\n",
    "    'Residential Medium': ['RM-2', 'RM-1'],\n",
    "    'Residential Low': ['RS', 'RL'],\n",
    "    'Residential Mixed': ['RMX'],\n",
    "    'Industrial': ['IP', 'IL', 'IH', 'IS', 'IBT'],\n",
    "    'Mixed Use': ['MU', 'EMX'],\n",
    "    'Agricultural': ['AG', 'AR'],\n",
    "    'Open Space': ['OS'],\n",
    "    'Planned': ['BLPD', 'MBPD', 'GQPD', 'MPD', 'CUPD', 'LJPD', 'LJSPD'],\n",
    "    'Transit': ['OTOP', 'OTRM', 'OTCC'],\n",
    "    'Other': ['UNZONED'],\n",
    "}\n",
    "\n",
    "def map_zoning_category(zone_code):\n",
    "    if isinstance(zone_code, str):  # Check if zone_code is a string\n",
    "        for category, prefixes in zoning_categories.items():\n",
    "            if any(zone_code.startswith(prefix) for prefix in prefixes):\n",
    "                return category\n",
    "    return 'Other'  # Return 'Other' for NaN or non-string values\n",
    "\n",
    "zoning_data.fillna({'zone_name':'Unknown'}, inplace=True)\n",
    "zoning_data['zone_type'] = zoning_data['zone_name'].apply(map_zoning_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d82a85-3157-4662-a7d1-2f5f59f2e866",
   "metadata": {},
   "source": [
    "### DMV Registration Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc99beaf-4c7e-413b-8741-464a7660e944",
   "metadata": {},
   "source": [
    "Gather information on the local registration information of vehicles according to the DMV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5399eed-cb88-44de-ad00-e1b8e6c0b425",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmv_data = pd.read_csv(\"shapefiles/vehicle-fuel-type-count-by-zip-code-2023.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd995cb-d0c2-4b88-8266-fb7859cfbe64",
   "metadata": {},
   "source": [
    "### Installation Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c98204f-89f7-48cf-87d9-4475c78ff7ee",
   "metadata": {},
   "source": [
    "- 2015 EVCS/EVSE Installation Costs: https://afdc.energy.gov/files/u/publication/evse_cost_report_2015.pdf\n",
    "  - Average public AC level 2 EVCS installation cost in San Diego is ~4000 (33% higher than average)\n",
    "    \n",
    "  - Average public DCFC EVCS installation cost ~24000 (33% figure would entail ~32000 cost in San Diego)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ca72e0-546b-4a44-ba15-3619dc6963b1",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ac6b9d-0cb9-4ea3-aaac-c0f7508345d2",
   "metadata": {},
   "source": [
    "### Zip Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5fc57a-7ab3-434f-adc3-24c1e073766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_gdf = gpd.read_file(\"data/population.geojson\", driver=\"GeoJSON\")\n",
    "income_gdf = gpd.read_file(\"data/income.geojson\", driver=\"GeoJSON\")\n",
    "# pop_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa96d0c8-37b1-4d93-8f46-2903ba85e503",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18edca62-6018-4cf5-9783-4abf3ed54724",
   "metadata": {},
   "source": [
    "### Parking Lots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf296487-7cad-4c62-954b-d7b064b2980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_shape = gpd.read_file(\"shapefiles/sdge_zcta.shp\")\n",
    "# zip_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6f1323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea9391",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e7fad8-b24f-4b3a-baff-5c613f7328c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "\n",
    "# Define the area of interest\n",
    "place_name = \"San Diego, California, USA\"\n",
    "\n",
    "# Query OSM for parking lots\n",
    "parking_lots = ox.geometries_from_place(place_name, tags={\"amenity\": \"parking\"})\n",
    "\n",
    "# Filter for public parking lots\n",
    "public_parking = parking_lots[\n",
    "    (parking_lots.get(\"parking\") == \"public\") |  # Explicitly public parking\n",
    "    (parking_lots.get(\"access\").isin([None, \"yes\", \"permissive\"]))  # Exclude private/restricted lots\n",
    "]\n",
    "\n",
    "# Convert to a GeoDataFrame\n",
    "public_parking_gdf = gpd.GeoDataFrame(public_parking, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "parking_cols = ['osmid','geometry','amenity','access','fee','parking','capacity']\n",
    "public_parking_gdf = public_parking_gdf.reset_index()[parking_cols]\n",
    "\n",
    "# Create a folium map centered on San Diego\n",
    "m = folium.Map(location=[32.7157, -117.1611], zoom_start=12)\n",
    "\n",
    "# Add public parking lots to the map\n",
    "for _, row in public_parking_gdf.iterrows():\n",
    "    if row.geometry.geom_type == \"Point\":\n",
    "        folium.CircleMarker(\n",
    "            location=[row.geometry.y, row.geometry.x],\n",
    "            radius=5,\n",
    "            color=\"blue\",\n",
    "            fill=True,\n",
    "            fill_color=\"blue\",\n",
    "            fill_opacity=0.6,\n",
    "            popup=\"Public Parking Lot\"\n",
    "        ).add_to(m)\n",
    "    elif row.geometry.geom_type in [\"Polygon\", \"MultiPolygon\"]:\n",
    "        folium.GeoJson(\n",
    "            row.geometry,\n",
    "            style_function=lambda x: {\"color\": \"blue\", \"fillColor\": \"blue\", \"weight\": 1, \"fillOpacity\": 0.4},\n",
    "            tooltip=\"Non-Private Parking Lot\"\n",
    "        ).add_to(m)\n",
    "print(public_parking_gdf.shape)\n",
    "print(public_parking_gdf.columns)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96facec-f9cb-44c3-9cb2-fd272df6245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_parking_gdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be31e63-88ad-41d4-842e-dea27ff13245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersections_gdf = intersections_gdf.set_crs(\"EPSG:4326\", allow_override=True)\n",
    "zoning_data = zoning_data.set_crs(\"EPSG:4326\", allow_override=True)\n",
    "\n",
    "# Perform the spatial join to map intersections to zoning data\n",
    "lots = gpd.sjoin(public_parking_gdf, zoning_data, how=\"left\", predicate=\"within\")\n",
    "\n",
    "# Drop irrelevant columns\n",
    "lots = lots.drop(columns=['index_right','imp_date','ordnum','objectid'])\n",
    "\n",
    "# Remove intersections with null zoning\n",
    "lots.loc[pd.isna(lots['zone_type']), 'zone_type'] = \"Multiple\"\n",
    "\n",
    "print(lots.shape)\n",
    "lots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30929ddf-48fa-4591-8ae0-180091524187",
   "metadata": {},
   "outputs": [],
   "source": [
    "lots.value_counts('zone_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f479d2b-b6a2-4800-8e13-4f18641d5ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import branca.colormap as cm\n",
    "\n",
    "# Create a folium map centered on San Diego\n",
    "m2 = folium.Map(location=[32.7157, -117.1611], zoom_start=12)\n",
    "\n",
    "# Define color mapping for zoning types\n",
    "color_mapping = {\n",
    "    'Commercial': 'lightblue',\n",
    "    'Office': 'lightgreen',\n",
    "    'Residential High': 'lightcoral',\n",
    "    'Residential Medium': 'khaki',\n",
    "    'Residential Low': 'lightyellow',\n",
    "    'Residential Mixed': 'lightpink',\n",
    "    'Industrial': 'lightgray',\n",
    "    'Mixed Use': 'lightseagreen',\n",
    "    'Agricultural': 'lightgoldenrodyellow',\n",
    "    'Open Space': 'lightblue',\n",
    "    'Planned': 'lightcyan',\n",
    "    'Transit': 'lavender',\n",
    "    'Other': 'gray',\n",
    "}\n",
    "\n",
    "# Function to style zoning polygons\n",
    "def zoning_style(feature):\n",
    "    zone_type = feature['properties']['zone_type']\n",
    "    color = color_mapping.get(zone_type, 'gray')  # Default to gray if not found\n",
    "    return {\n",
    "        'fillColor': color, \n",
    "        'color': 'black', \n",
    "        'weight': 1,\n",
    "        'fillOpacity': 0.3,\n",
    "    }\n",
    "    \n",
    "# Add zoning overlay to the map\n",
    "folium.GeoJson(\n",
    "    zoning_data,  # GeoJSON file with zoning polygons\n",
    "    style_function=zoning_style\n",
    ").add_to(m2)\n",
    "\n",
    "# Add a legend for zoning categories\n",
    "opacity = 0.8\n",
    "legend_html = f\"\"\"\n",
    "<div style=\"position: fixed; \n",
    "             top: 10px; left: 10px; \n",
    "             width: 200px; height: auto; \n",
    "             background-color: rgba(255, 255, 255, {opacity}); \n",
    "             border:2px solid grey; \n",
    "             z-index: 9999; \n",
    "             font-size:14px;\">\n",
    "    <b>Zoning Categories</b><br>\n",
    "    <div style=\"line-height: 1.5;\">\n",
    "\"\"\"\n",
    "for category, color in color_mapping.items():\n",
    "    legend_html += f'<div><i style=\"background:{color}; width: 20px; height: 20px; display: inline-block;\"></i> {category}</div>'\n",
    "legend_html += \"</div></div>\"\n",
    "m2.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "# Add parking lots with zoning type tooltips\n",
    "for _, row in lots.iterrows():\n",
    "    zone_type = row['zone_type'] if 'zone_type' in row else \"Unknown\"\n",
    "    \n",
    "    if row.geometry.geom_type == \"Point\":\n",
    "        folium.CircleMarker(\n",
    "            location=[row.geometry.y, row.geometry.x],\n",
    "            radius=5,\n",
    "            color=\"green\",\n",
    "            fill=True,\n",
    "            fill_color=\"green\",\n",
    "            fill_opacity=0.7,\n",
    "            popup=f\"Zone Type: {zone_type}\",\n",
    "            tooltip=f\"Zone: {zone_type}\"\n",
    "        ).add_to(m2)\n",
    "    \n",
    "    elif row.geometry.geom_type in [\"Polygon\", \"MultiPolygon\"]:\n",
    "        folium.GeoJson(\n",
    "            row.geometry,\n",
    "            style_function=lambda x: {\"color\": \"green\", \"fillColor\": \"green\", \"weight\": 1, \"fillOpacity\": 0.4},\n",
    "            tooltip=f\"Zone: {zone_type}\"\n",
    "        ).add_to(m2)\n",
    "\n",
    "\n",
    "# Save map as an HTML file (optional)\n",
    "m2.save(\"parking_lots_with_zoning.html\")\n",
    "\n",
    "# Display the map\n",
    "print(\"Map of Public Parking Lots Overlaid by City Zoning\")\n",
    "m2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242dd9ae-24f4-4129-b2d1-cb1896555650",
   "metadata": {},
   "source": [
    "### AFDC Charging Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee8c90-44f7-415b-9981-e556ffe4ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CS - Charging Stations\n",
    "cs = pd.DataFrame(data['fuel_stations'])\n",
    "cs = cs[cs['zip'] != 'CA']\n",
    "cs['zip'] = cs['zip'].astype(int)\n",
    "cs = cs[cs['zip'].isin(sdge_zips)]\n",
    "cs = cs[cs['access_code']==\"public\"]\n",
    "cs = cs[[\n",
    "    'id', 'access_code','facility_type','latitude','longitude','zip','ev_connector_types',\n",
    "    'ev_dc_fast_num','ev_level1_evse_num','ev_level2_evse_num','ev_network'\n",
    "]]\n",
    "cs = cs.reset_index(drop=True)\n",
    "\n",
    "print(cs.shape)\n",
    "# cs.columns\n",
    "cs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3221bdb1-65ba-4a90-aaf6-5494647b0d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create a geometry column for EV chargers\n",
    "geometry = [Point(xy) for xy in zip(cs['longitude'], cs['latitude'])]\n",
    "cs_gdf = gpd.GeoDataFrame(cs, geometry=geometry)\n",
    "cs_gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "# Create a one-hot encoding of the 'ev_connector_types' column\n",
    "# Step 1: Explode the 'ev_connector_types' column to create individual rows\n",
    "cs_gdf_exploded = cs_gdf.explode('ev_connector_types', ignore_index=True)\n",
    "\n",
    "# Step 2: One-hot encode the exploded 'ev_connector_types' column\n",
    "one_hot_encoded = pd.get_dummies(cs_gdf_exploded['ev_connector_types'], prefix='connector')\n",
    "connector_cols = list(one_hot_encoded.columns)\n",
    "\n",
    "# Step 3: Combine the one-hot encoded DataFrame with the exploded DataFrame\n",
    "cs_gdf_exploded = pd.concat([cs_gdf_exploded, one_hot_encoded], axis=1)\n",
    "cs_gdf_exploded = cs_gdf_exploded.groupby('id')[connector_cols].sum().reset_index()\n",
    "\n",
    "# Step 4: Aggregate back to the original DataFrame, summing up the one-hot columns\n",
    "cs_gdf = cs_gdf.merge(cs_gdf_exploded, how='left', on='id')\n",
    "cs_gdf = cs_gdf.drop(columns=['ev_connector_types'])\n",
    "\n",
    "\\\n",
    "\n",
    "# Check the resulting DataFrame\n",
    "print(cs_gdf.shape)\n",
    "cs_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693bf5da-c366-4850-a547-3e7846a25993",
   "metadata": {},
   "outputs": [],
   "source": [
    "lots_cs = gpd.read_file(\"lots_cs.geojson\")\n",
    "# lots_cs = lots_cs.iloc[:,1:]\n",
    "lots_cs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e994c1-bfc8-4c51-9da4-ea709f2e8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl = gpd.read_file(\"data/roads_datasd.geojson\")\n",
    "print(rl.shape)\n",
    "rl.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3bfded-6759-4e4d-8083-93f3124246ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = pd.read_csv(\"data/traffic_counts_datasd.csv\")\n",
    "# print(tc.shape)\n",
    "tc['date_count'] = pd.to_datetime(tc['date_count'])\n",
    "tc_sorted = tc.sort_values(by=['street_name', 'date_count'], ascending=[True, False])\n",
    "tc_recent = tc_sorted.drop_duplicates(subset='street_name')\n",
    "print(tc_recent.shape)\n",
    "tc_recent.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22192819-83ed-4c73-a6b7-f1d3555668a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import MultiLineString\n",
    "rl = rl.to_crs(epsg=4326)\n",
    "\n",
    "# Merge based on street names and ensure the result is a GeoDataFrame\n",
    "tc_rel = tc_recent[['id','street_name','total_count']]\n",
    "rl_rel = rl[['rd20full','geometry']]\n",
    "merged = tc_rel.merge(rl_rel, left_on='street_name', right_on='rd20full', how='inner')\n",
    "\n",
    "# Convert the merged DataFrame to a GeoDataFrame\n",
    "road_traffic = gpd.GeoDataFrame(merged, geometry='geometry')\n",
    "\n",
    "# Group by 'id', aggregate geometries into MultiLineString, and calculate the average 'total_count'\n",
    "road_traffic_grouped = road_traffic.groupby('street_name').agg({\n",
    "    'geometry': lambda x: MultiLineString(x.tolist()),\n",
    "    'total_count': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Convert the grouped DataFrame to a GeoDataFrame and set the CRS\n",
    "road_traffic_grouped = gpd.GeoDataFrame(road_traffic_grouped, geometry='geometry')\n",
    "road_traffic_grouped.crs = 'EPSG:4326'\n",
    "\n",
    "# Print the final road_traffic_grouped GeoDataFrame and count of NaN in 'total_count'\n",
    "print(road_traffic_grouped['total_count'].isna().sum())\n",
    "road_traffic_grouped.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba7db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lots_cs = gpd.read_file(\"lots_cs.geojson\")\n",
    "\n",
    "def get_nearest_charger_zip(lot_row, cs_gdf):\n",
    "    if isinstance(lot_row.geometry, Point):\n",
    "        lot_coords = (lot_row.geometry.y, lot_row.geometry.x)\n",
    "    else:\n",
    "        lot_coords = (lot_row.geometry.centroid.y, lot_row.geometry.centroid.x)\n",
    "    \n",
    "    distances = cs_gdf.apply(\n",
    "        lambda row: geodesic(lot_coords, (row.latitude, row.longitude)).meters, \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    nearest_index = distances.idxmin()\n",
    "    return cs_gdf.loc[nearest_index, 'zip']\n",
    "\n",
    "lots_cs['zip'] = lots_cs.apply(lambda row: get_nearest_charger_zip(row, cs_gdf), axis=1)\n",
    "\n",
    "cs_lots_traffic = lots_cs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453b7299-bf68-4669-9624-1ac51ae5921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Assuming you have your dataframes ready: road_traffic and cs_lots\n",
    "# Ensure they both have a consistent coordinate reference system (CRS)\n",
    "road_traffic_grouped = road_traffic_grouped.to_crs('EPSG:4326')\n",
    "lots_cs = lots_cs.to_crs('EPSG:4326')\n",
    "\n",
    "cs_lots_traffic = lots_cs.copy()\n",
    "\n",
    "# Re-project to a projected CRS for accurate buffer operation (e.g., EPSG:3857)\n",
    "buffered_cs_lots = lots_cs.to_crs('EPSG:3857')\n",
    "road_traffic_projected = road_traffic_grouped.to_crs('EPSG:3857')\n",
    "\n",
    "# Buffer the parking lots to consider \"adjacent\" roads within a given distance (e.g., 5 meters)\n",
    "buffered_cs_lots['geometry'] = buffered_cs_lots['geometry'].buffer(50)\n",
    "\n",
    "# Calculate the total adjacent traffic volume for each parking lot\n",
    "def calculate_total_adjacent_traffic(parking_lot, road_traffic_grouped):\n",
    "    total_traffic = 0\n",
    "    for road in road_traffic_grouped.itertuples():\n",
    "        if parking_lot.intersects(road.geometry):\n",
    "            total_traffic += road.total_count\n",
    "    return total_traffic\n",
    "\n",
    "# Add a new column to cs_lots for total adjacent traffic\n",
    "cs_lots_traffic['traffic'] = buffered_cs_lots.apply(\n",
    "    lambda row: calculate_total_adjacent_traffic(row['geometry'], road_traffic_projected), axis=1\n",
    ").astype(int)  # Calculate total adjacent traffic using roads.\n",
    "\n",
    "# Re-project back to the original CRS\n",
    "cs_lots_traffic = cs_lots_traffic.to_crs('EPSG:4326')\n",
    "\n",
    "# Print the results\n",
    "cs_lots_traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db97fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_lots_traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0ddf9d-97b8-4638-9759-07b2e34e4073",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_lots_traffic['traffic'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f000b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_gdf = gpd.read_file(\"data/population.geojson\")\n",
    "pop_gdf.set_crs(\"EPSG:3857\", allow_override=True, inplace=True)\n",
    "\n",
    "income_gdf = gpd.read_file(\"data/income.geojson\")\n",
    "income_gdf.set_crs(\"EPSG:3857\", allow_override=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8199ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_gdf = pop_gdf.to_crs(\"EPSG:4326\")\n",
    "income_gdf = income_gdf.to_crs(\"EPSG:4326\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21752d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lots_proj = lots.to_crs(\"EPSG:3857\")\n",
    "\n",
    "lots_proj[\"geometry\"] = lots_proj.geometry.buffer(50)\n",
    "\n",
    "\n",
    "lots_buffer = lots_proj.to_crs(\"EPSG:4326\")\n",
    "\n",
    "\n",
    "print(\"lots_buffer bounds:\", lots_buffer.total_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f0954",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lots_pop = gpd.sjoin(lots_buffer, pop_gdf[['Population', 'geometry']], how='left', predicate='intersects')\n",
    "\n",
    "lots_pop = lots_pop.drop(columns=['index_right'], errors='ignore')\n",
    "\n",
    "lots_pop_income = gpd.sjoin(lots_pop, income_gdf[['Median Income', 'geometry']], how='left', predicate='intersects')\n",
    "lots_pop_income = lots_pop_income.drop(columns=['index_right'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835db3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "lots_pop_income['Median Income'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a598c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lots_pop_income['Median Income'].fillna((lots_pop_income['Median Income'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a2ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lots_pop_income_agg = lots_pop_income.groupby('osmid').agg({\n",
    "    'geometry': 'first',  \n",
    "    'amenity': 'first',  \n",
    "    'access': 'first',\n",
    "    'fee': 'first',\n",
    "    'parking': 'first',\n",
    "    'capacity': 'first',\n",
    "    'zone_name': 'first',\n",
    "    'zone_type': 'first',\n",
    "    'Population': 'mean',       \n",
    "    'Median Income': 'mean'   \n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2360a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lots_pop_income_agg['Population'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfded587",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_features = cs_lots_traffic.merge(lots_pop_income_agg[['osmid', 'Population', 'Median Income']], on='osmid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef050bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoning_suitability = {\n",
    "    'Commercial': 1.0, \n",
    "    'Office': 0.8, \n",
    "    'Mixed Use': 0.7, \n",
    "    'Transit': 0.6,\n",
    "    'Industrial': 0.5, \n",
    "    'Planned': 0.5, \n",
    "    'Other': 0.4, \n",
    "    'Residential High': 0.3,\n",
    "    'Residential Medium': 0.2, \n",
    "    'Residential Low': 0.1, \n",
    "    'Agricultural': 0.0,\n",
    "    'Open Space': 0.0,\n",
    "    'Multiple': 0.7 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76db578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_features['zoning_score'] = merged_features['zone_type'].map(zoning_suitability) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551721aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cfb2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "# from shapely.geometry import Point\n",
    "\n",
    "# # Step 1: Load your datasets (adjust names as per your code)\n",
    "# # Assuming cs_gdf is the chargers GeoDataFrame and cs_lots_scored is the parking lots GeoDataFrame\n",
    "# chargers = cs_gdf  # Chargers GeoDataFrame\n",
    "# parking_lots = cs_lots_scored  # Parking lots GeoDataFrame\n",
    "\n",
    "# # Step 2: Ensure both GeoDataFrames use the same coordinate reference system (CRS)\n",
    "# # Start with WGS84 (EPSG:4326), then project to a meter-based CRS for accurate distances\n",
    "# chargers = chargers.to_crs(epsg=4326)\n",
    "# parking_lots = parking_lots.to_crs(epsg=4326)\n",
    "\n",
    "# # Project to UTM zone 11N (EPSG:32611) for San Diego, assuming that's your area\n",
    "# chargers_proj = chargers.to_crs(epsg=32611)\n",
    "# parking_lots_proj = parking_lots.to_crs(epsg=32611)\n",
    "\n",
    "# # Step 3: Buffer point parking lots to create small polygons (e.g., 10 meters radius)\n",
    "# def buffer_if_point(geom, buffer_distance=10):\n",
    "#     if geom.geom_type == 'Point':\n",
    "#         return geom.buffer(buffer_distance)\n",
    "#     else:\n",
    "#         return geom\n",
    "\n",
    "# parking_lots_proj['geometry'] = parking_lots_proj['geometry'].apply(\n",
    "#     lambda g: buffer_if_point(g, buffer_distance=10)\n",
    "# )\n",
    "\n",
    "# # Step 4: Perform a spatial join to find chargers within each parking lot\n",
    "# chargers_in_lots = gpd.sjoin(\n",
    "#     chargers_proj,\n",
    "#     parking_lots_proj,\n",
    "#     how='inner',\n",
    "#     predicate='within'\n",
    "# )\n",
    "\n",
    "# # Step 5: Count chargers per parking lot\n",
    "# # Group by parking lot identifier ('osmid' from parking_lots_proj)\n",
    "# charger_counts = chargers_in_lots.groupby('osmid').size().reset_index(name='charger_count')\n",
    "\n",
    "# # Step 6: Merge charger counts back into the parking lots GeoDataFrame\n",
    "# parking_lots_proj = parking_lots_proj.merge(\n",
    "#     charger_counts,\n",
    "#     on='osmid',\n",
    "#     how='left'\n",
    "# )\n",
    "\n",
    "# # Step 7: Fill missing values (no chargers) with 0\n",
    "# parking_lots_proj['charger_count'] = parking_lots_proj['charger_count'].fillna(0).astype(int)\n",
    "\n",
    "# # Step 8: Create the binary target variable\n",
    "# parking_lots_proj['has_charger'] = (parking_lots_proj['charger_count'] > 0).astype(int)\n",
    "\n",
    "# # Step 9: Project back to WGS84 and update the original dataset\n",
    "# parking_lots = parking_lots_proj.to_crs(epsg=4326)\n",
    "# merged_features['has_charger'] = parking_lots['has_charger']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7dbea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50d0a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_features['demand_score'] = (\n",
    "#     merged_features['distance_score'] +\n",
    "#     merged_features['radius_score'] +\n",
    "#     merged_features['cs_total_score'] +\n",
    "#     merged_features['traffic_score'] +\n",
    "#     merged_features['population_score'] +\n",
    "#     merged_features['income_score'] +\n",
    "#     merged_features['zoning_score']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09afe95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Calculate percentile rank for each feature\n",
    "features = ['distance_to_nearest_charger', 'chargers_in_radius', 'cs_total', 'traffic', 'Population', 'Median Income']\n",
    "for feature in features:\n",
    "    merged_features[f'percentile_{feature}'] = merged_features[feature].rank(pct=True)\n",
    "\n",
    "# Manually assign weights based on expert knowledge\n",
    "merged_features['distance_score'] = merged_features['percentile_distance_to_nearest_charger'] * 0.5\n",
    "merged_features['radius_score'] = merged_features['percentile_chargers_in_radius'] * -0.3\n",
    "merged_features['cs_total_score'] = merged_features['percentile_cs_total'] * -0.2\n",
    "merged_features['traffic_score'] = merged_features['percentile_traffic'] * 0.1\n",
    "merged_features['population_score'] = merged_features['percentile_Population'] * 0.2\n",
    "merged_features['income_score'] = merged_features['percentile_Median Income'] * 0.1\n",
    "\n",
    "# Calculate the combined demand score including the traffic score\n",
    "merged_features['demand_score'] = (\n",
    "    merged_features['distance_score'] +\n",
    "    merged_features['radius_score'] +\n",
    "    merged_features['cs_total_score'] +\n",
    "    merged_features['traffic_score'] +\n",
    "    merged_features['population_score'] +\n",
    "    merged_features['income_score'] +\n",
    "    merged_features['zoning_score']\n",
    ")\n",
    "\n",
    "# Normalize the demand score to a scale of 0 to 1\n",
    "min_max_scaler = MinMaxScaler()\n",
    "merged_features['demand_score'] = min_max_scaler.fit_transform(merged_features[['demand_score']])\n",
    "print(merged_features.shape)\n",
    "merged_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ff262",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aee97dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Import necessary libraries\n",
    "import folium\n",
    "import branca.colormap as cm\n",
    "\n",
    "# Define a colormap for the demand score\n",
    "demand_score_colormap = cm.linear.YlOrRd_09.scale(merged_features['demand_score'].min(), merged_features['demand_score'].max())\n",
    "\n",
    "# Ensure CRS is WGS84 (EPSG:4326) for compatibility with Folium\n",
    "merged_features = merged_features.to_crs(epsg=4326)\n",
    "\n",
    "# Initialize the folium map centered on San Diego\n",
    "m4 = folium.Map(location=[32.7157, -117.1611], zoom_start=11, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Add the color scale legend to the map\n",
    "demand_score_colormap.caption = \"Demand Score\"\n",
    "demand_score_colormap.add_to(m4)\n",
    "\n",
    "# Add parking lots to the map\n",
    "for _, row in merged_features.iterrows():\n",
    "    color = demand_score_colormap(row['demand_score'])\n",
    "    \n",
    "    # Create detailed tooltip information\n",
    "    tooltip_text = (\n",
    "        f\"Parking Lot ID: {row.osmid}<br>\"\n",
    "        f\"Demand Score: {row.demand_score:.2f}<br>\"\n",
    "        f\"Zone Name: {row.zone_name}<br>\"\n",
    "        f\"Zone Type: {row.zone_type}<br>\"\n",
    "        f\"ZIP Code: {row.zip}<br>\"\n",
    "        f\"------Geographic Features------<br>\"\n",
    "        f\"Distance to Nearest Charger: {row.distance_to_nearest_charger:.2f} meters<br>\"\n",
    "        f\"Chargers in Radius: {row.chargers_in_radius}<br>\"\n",
    "        f\"Charging Points Total: {row.cs_total}<br>\"\n",
    "        f\"Traffic Volume: {row.traffic}<br>\"\n",
    "        f\"Population: {row.Population}<br>\"\n",
    "        f\"Median Income: {row['Median Income']}<br>\"\n",
    "        f\"------Percentile Scores------<br>\"\n",
    "        f\"Distance Percentile: {row.percentile_distance_to_nearest_charger:.2f}<br>\"\n",
    "        f\"Radius Chargers Percentile: {row.percentile_chargers_in_radius:.2f}<br>\"\n",
    "        f\"Total Chargers Percentile: {row.percentile_cs_total:.2f}<br>\"\n",
    "        f\"Traffic Percentile: {row.percentile_traffic:.2f}<br>\"\n",
    "        f\"Population Percentile: {row.percentile_Population:.2f}<br>\"\n",
    "        f\"Income Percentile: {row['percentile_Median Income']:.2f}<br>\"\n",
    "        f\"------Score Components------<br>\"\n",
    "        f\"Distance Score: {row.distance_score:.2f}<br>\"\n",
    "        f\"Radius Score: {row.radius_score:.2f}<br>\"\n",
    "        f\"Total Charging Points Score: {row.cs_total_score:.2f}<br>\"\n",
    "        f\"Traffic Score: {row.traffic_score:.2f}<br>\"\n",
    "        f\"Population Score: {row.population_score:.2f}<br>\"\n",
    "        f\"Income Score: {row.income_score:.2f}<br>\"\n",
    "        f\"Zoning Score: {row.zoning_score:.2f}\"\n",
    "    )\n",
    "\n",
    "    if isinstance(row.geometry, Point):\n",
    "        # Add a small circle for point geometries\n",
    "        folium.Circle(\n",
    "            location=(row.geometry.y, row.geometry.x),\n",
    "            radius=20,  # Small circle radius\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_opacity=0.7,\n",
    "            tooltip=folium.Tooltip(tooltip_text),\n",
    "        ).add_to(m4)\n",
    "    else:\n",
    "        # Add the parking lot geometry to the map\n",
    "        folium.GeoJson(\n",
    "            row.geometry,\n",
    "            style_function=lambda feature, color=color: {\n",
    "                'fillColor': color,\n",
    "                'color': color,\n",
    "                'weight': 1,\n",
    "                'fillOpacity': 0.7,\n",
    "                'opacity': 0.7\n",
    "            },\n",
    "            tooltip=folium.Tooltip(tooltip_text),\n",
    "        ).add_to(m4)\n",
    "\n",
    "# Add legend explanation\n",
    "legend_html = '''\n",
    "<div style=\"position: fixed; \n",
    "     bottom: 50px; left: 50px; width: 250px; height: auto;\n",
    "     border:2px solid grey; z-index:9999; font-size:14px;\n",
    "     background-color: white; padding: 10px; border-radius: 5px;\">\n",
    "     <b>Demand Score Explanation</b><br>\n",
    "     Darker colors indicate higher demand for new charging stations<br>\n",
    "     Score factors considered:<br>\n",
    "     - Distance to nearest charger (weight: 0.5)<br>\n",
    "     - Chargers in radius (weight: -0.3)<br>\n",
    "     - Existing charging points (weight: -0.2)<br>\n",
    "     - Traffic volume (weight: 0.1)<br>\n",
    "     - Population density (weight: 0.2)<br>\n",
    "     - Income level (weight: 0.1)<br>\n",
    "</div>\n",
    "'''\n",
    "m4.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "# Add title at the top\n",
    "title_html = '''\n",
    "<h3 align=\"center\" style=\"font-size:20px; font-family: 'Arial'; margin-top: 10px;\">\n",
    "    <b>Parking Lot Charging Station Demand Score Map</b>\n",
    "</h3>\n",
    "'''\n",
    "m4.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "# Display the map\n",
    "print(\"Parking Lot Demand Score Map - Darker colors indicate higher demand for new charging stations\")\n",
    "m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07106b9b-6db3-4f83-9e96-5595f69021a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define a colormap for the demand score\n",
    "demand_score_colormap = cm.linear.YlOrRd_09.scale(cs_lots_scored['demand_score'].min(), cs_lots_scored['demand_score'].max())\n",
    "\n",
    "# Ensure CRS is WGS84 (EPSG:4326) for compatibility with Folium\n",
    "cs_lots_scored = merged_features.to_crs(epsg=4326)\n",
    "\n",
    "# Initialize the folium map centered on San Diego\n",
    "m4 = folium.Map(location=[32.7157, -117.1611], zoom_start=11, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Add the color scale legend to the map\n",
    "demand_score_colormap.caption = \"Demand Score\"\n",
    "demand_score_colormap.add_to(m4)\n",
    "\n",
    "# Add parking lots to the map\n",
    "for _, row in cs_lots_scored.iterrows():\n",
    "    color = demand_score_colormap(row['demand_score'])\n",
    "    \n",
    "    tooltip_text = (\n",
    "        f\"Parking Lot OSMID: {row.osmid}<br>\"\n",
    "        f\"Demand Score: {row.demand_score:.2f}<br>\"\n",
    "        f\"Zone Name: {row.zone_name}<br>\"\n",
    "        f\"Distance to Nearest Charger: {row.distance_to_nearest_charger:.2f} meters<br>\"\n",
    "        f\"Chargers in Radius: {row.chargers_in_radius}<br>\"\n",
    "        f\"CS Total: {row.cs_total}<br>\"\n",
    "        f\"Traffic: {row.traffic}<br>\"\n",
    "        f\"Percentile Distance Score: {row.percentile_distance_to_nearest_charger:.2f}<br>\"\n",
    "        f\"Percentile Radius Score: {row.percentile_chargers_in_radius:.2f}<br>\"\n",
    "        f\"Percentile CS Total Score: {row.percentile_cs_total:.2f}<br>\"\n",
    "        f\"Distance Score: {row.distance_score:.2f}<br>\"\n",
    "        f\"Radius Score: {row.radius_score:.2f}<br>\"\n",
    "        f\"CS Total Score: {row.cs_total_score:.2f}\"\n",
    "    )\n",
    "\n",
    "    if isinstance(row.geometry, Point):\n",
    "        # Add a small circle for point geometries\n",
    "        folium.Circle(\n",
    "            location=(row.geometry.y, row.geometry.x),\n",
    "            radius=20,  # Small circle radius\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_opacity=0.6,\n",
    "            tooltip=folium.Tooltip(tooltip_text),\n",
    "        ).add_to(m4)\n",
    "    else:\n",
    "        # Add the parking lot geometry to the map\n",
    "        folium.GeoJson(\n",
    "            row.geometry,\n",
    "            style_function=lambda feature, color=color: {\n",
    "                'fillColor': color,\n",
    "                'color': color,\n",
    "                'weight': 1,\n",
    "                'fillOpacity': 0.6,\n",
    "                'opacity': 0.6\n",
    "            },\n",
    "            tooltip=folium.Tooltip(tooltip_text),\n",
    "        ).add_to(m4)\n",
    "\n",
    "# Display the map\n",
    "print(\"Map of parking lots with color-coded demand scores\")\n",
    "m4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb137f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_features.groupby('zip').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a731349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import folium\n",
    "import branca.colormap as cm\n",
    "from folium.plugins import Draw, MousePosition\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Define a colormap for the demand score\n",
    "demand_score_colormap = cm.linear.YlOrRd_09.scale(merged_features['demand_score'].min(), merged_features['demand_score'].max())\n",
    "\n",
    "# Ensure CRS is WGS84 (EPSG:4326) for compatibility with Folium\n",
    "merged_features = merged_features.to_crs(epsg=4326)\n",
    "\n",
    "# Initialize the folium map centered on San Diego\n",
    "m4 = folium.Map(location=[32.7157, -117.1611], zoom_start=11, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Add the color scale legend to the map\n",
    "demand_score_colormap.caption = \"Demand Score\"\n",
    "demand_score_colormap.add_to(m4)\n",
    "\n",
    "# Add mouse position to show coordinates\n",
    "MousePosition().add_to(m4)\n",
    "\n",
    "# Add drawing tools\n",
    "Draw(export=True).add_to(m4)\n",
    "\n",
    "# Create feature groups for regular and highlighted parking lots\n",
    "regular_parking_fg = folium.FeatureGroup(name=\"All Parking Lots\")\n",
    "highlighted_parking_fg = folium.FeatureGroup(name=\"Recommended Parking Lots\")\n",
    "\n",
    "# Add parking lots to the regular feature group\n",
    "for _, row in merged_features.iterrows():\n",
    "    color = demand_score_colormap(row['demand_score'])\n",
    "    \n",
    "    # Create detailed tooltip information\n",
    "    tooltip_text = (\n",
    "        f\"Parking Lot ID: {row.osmid}<br>\"\n",
    "        f\"Demand Score: {row.demand_score:.2f}<br>\"\n",
    "        f\"Zone Name: {row.zone_name}<br>\"\n",
    "        f\"Zone Type: {row.zone_type}<br>\"\n",
    "        f\"ZIP Code: {row.zip}<br>\"\n",
    "        f\"------Geographic Features------<br>\"\n",
    "        f\"Distance to Nearest Charger: {row.distance_to_nearest_charger:.2f} meters<br>\"\n",
    "        f\"Chargers in Radius: {row.chargers_in_radius}<br>\"\n",
    "        f\"Charging Points Total: {row.cs_total}<br>\"\n",
    "        f\"Traffic Volume: {row.traffic}<br>\"\n",
    "        f\"Population: {row.Population}<br>\"\n",
    "        f\"Median Income: {row['Median Income']}<br>\"\n",
    "        f\"------Percentile Scores------<br>\"\n",
    "        f\"Distance Percentile: {row.percentile_distance_to_nearest_charger:.2f}<br>\"\n",
    "        f\"Radius Chargers Percentile: {row.percentile_chargers_in_radius:.2f}<br>\"\n",
    "        f\"Total Chargers Percentile: {row.percentile_cs_total:.2f}<br>\"\n",
    "        f\"Traffic Percentile: {row.percentile_traffic:.2f}<br>\"\n",
    "        f\"Population Percentile: {row.percentile_Population:.2f}<br>\"\n",
    "        f\"Income Percentile: {row['percentile_Median Income']:.2f}<br>\"\n",
    "        f\"------Score Components------<br>\"\n",
    "        f\"Distance Score: {row.distance_score:.2f}<br>\"\n",
    "        f\"Radius Score: {row.radius_score:.2f}<br>\"\n",
    "        f\"Total Charging Points Score: {row.cs_total_score:.2f}<br>\"\n",
    "        f\"Traffic Score: {row.traffic_score:.2f}<br>\"\n",
    "        f\"Population Score: {row.population_score:.2f}<br>\"\n",
    "        f\"Income Score: {row.income_score:.2f}<br>\"\n",
    "        f\"Zoning Score: {row.zoning_score:.2f}\"\n",
    "    )\n",
    "\n",
    "    if isinstance(row.geometry, Point):\n",
    "        # Add a small circle for point geometries\n",
    "        folium.Circle(\n",
    "            location=(row.geometry.y, row.geometry.x),\n",
    "            radius=20,  # Small circle radius\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_opacity=0.7,\n",
    "            tooltip=folium.Tooltip(tooltip_text),\n",
    "        ).add_to(regular_parking_fg)\n",
    "    else:\n",
    "        # Add the parking lot geometry to the map\n",
    "        folium.GeoJson(\n",
    "            row.geometry,\n",
    "            style_function=lambda feature, color=color: {\n",
    "                'fillColor': color,\n",
    "                'color': color,\n",
    "                'weight': 1,\n",
    "                'fillOpacity': 0.7,\n",
    "                'opacity': 0.7\n",
    "            },\n",
    "            tooltip=folium.Tooltip(tooltip_text),\n",
    "        ).add_to(regular_parking_fg)\n",
    "\n",
    "# Add the regular feature group to the map\n",
    "regular_parking_fg.add_to(m4)\n",
    "\n",
    "# Add layer control to toggle feature groups\n",
    "folium.LayerControl().add_to(m4)\n",
    "\n",
    "# Add legend explanation\n",
    "legend_html = '''\n",
    "<div style=\"position: fixed; \n",
    "     bottom: 50px; left: 50px; width: 250px; height: auto;\n",
    "     border:2px solid grey; z-index:9999; font-size:14px;\n",
    "     background-color: white; padding: 10px; border-radius: 5px;\">\n",
    "     <b>Demand Score Explanation</b><br>\n",
    "     Darker colors indicate higher demand for new charging stations<br>\n",
    "     Score factors considered:<br>\n",
    "     - Distance to nearest charger (weight: 0.5)<br>\n",
    "     - Chargers in radius (weight: -0.3)<br>\n",
    "     - Existing charging points (weight: -0.2)<br>\n",
    "     - Traffic volume (weight: 0.1)<br>\n",
    "     - Population density (weight: 0.2)<br>\n",
    "     - Income level (weight: 0.1)<br>\n",
    "</div>\n",
    "'''\n",
    "m4.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "# Add title at the top\n",
    "title_html = '''\n",
    "<h3 align=\"center\" style=\"font-size:20px; font-family: 'Arial'; margin-top: 10px;\">\n",
    "    <b>Parking Lot Charging Station Demand Score Map</b>\n",
    "</h3>\n",
    "'''\n",
    "m4.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "# Prepare data for JavaScript filtering\n",
    "# Create a simplified GeoJSON representation of the merged_features dataframe\n",
    "# Convert merged_features GeoDataFrame to GeoJSON format\n",
    "geojson_data = json.loads(merged_features.to_json())\n",
    "\n",
    "# Extract just the properties we need for each feature\n",
    "js_data = []\n",
    "for feature in geojson_data['features']:\n",
    "    props = feature['properties']\n",
    "    if props:\n",
    "        item = {\n",
    "            'osmid': props.get('osmid'),\n",
    "            'zip': props.get('zip'),\n",
    "            'demand_score': props.get('demand_score'),\n",
    "            'geometry': feature['geometry']\n",
    "        }\n",
    "        js_data.append(item)\n",
    "\n",
    "# Create a JavaScript function to filter and highlight the recommended locations\n",
    "js_filter_code = \"\"\"\n",
    "// Define the filter function\n",
    "function filterByZipAndCount(zip, count) {\n",
    "    // Clear previous recommendations\n",
    "    document.getElementById('recommendations').innerHTML = '';\n",
    "    \n",
    "    // Get the map object\n",
    "    var map = this.map;\n",
    "    \n",
    "    // Clear previous highlighted feature group and create a new one\n",
    "    map.eachLayer(function(layer) {\n",
    "        if (layer.options && layer.options.name === 'Recommended Parking Lots') {\n",
    "            map.removeLayer(layer);\n",
    "        }\n",
    "    });\n",
    "    \n",
    "    var highlightedGroup = L.featureGroup().addTo(map);\n",
    "    highlightedGroup.options = {name: 'Recommended Parking Lots'};\n",
    "    \n",
    "    // Get all data from the merged_features DataFrame\n",
    "    var parkingData = %s;\n",
    "    \n",
    "    // Filter data by ZIP code if provided\n",
    "    var filteredData = parkingData;\n",
    "    if (zip && zip.trim() !== '') {\n",
    "        filteredData = parkingData.filter(function(item) {\n",
    "            return item.zip && item.zip.toString() === zip.trim();\n",
    "        });\n",
    "    }\n",
    "    \n",
    "    // Sort by demand score (descending)\n",
    "    filteredData.sort(function(a, b) {\n",
    "        return b.demand_score - a.demand_score;\n",
    "    });\n",
    "    \n",
    "    // Limit to the requested number of results\n",
    "    var numRecommendations = parseInt(count) || 5;  // Default to 5 if not specified\n",
    "    var topRecommendations = filteredData.slice(0, numRecommendations);\n",
    "    \n",
    "    // Add recommendations to the list and map\n",
    "    topRecommendations.forEach(function(item, index) {\n",
    "        // Add to recommendations list\n",
    "        var recItem = document.createElement('div');\n",
    "        recItem.style.padding = '5px';\n",
    "        recItem.style.borderBottom = '1px solid #ccc';\n",
    "        recItem.innerHTML = '<b>#' + (index + 1) + ':</b> ID: ' + item.osmid + \n",
    "                          ', Score: ' + item.demand_score.toFixed(2) + \n",
    "                          ', ZIP: ' + item.zip;\n",
    "        document.getElementById('recommendations').appendChild(recItem);\n",
    "        \n",
    "        // Add highlighted marker to the map\n",
    "        var coords = item.geometry.coordinates;\n",
    "        var lat, lng;\n",
    "        \n",
    "        if (item.geometry.type === 'Point') {\n",
    "            lng = coords[0];\n",
    "            lat = coords[1];\n",
    "            \n",
    "            L.circleMarker([lat, lng], {\n",
    "                radius: 25,\n",
    "                color: '#FF4500',\n",
    "                weight: 3,\n",
    "                opacity: 1,\n",
    "                fillColor: '#FF4500',\n",
    "                fillOpacity: 0.7\n",
    "            }).bindTooltip(\n",
    "                'Rank #' + (index + 1) + '<br>' +\n",
    "                'ID: ' + item.osmid + '<br>' +\n",
    "                'Demand Score: ' + item.demand_score.toFixed(2) + '<br>' +\n",
    "                'ZIP: ' + item.zip\n",
    "            ).addTo(highlightedGroup);\n",
    "        } else {\n",
    "            // For polygons and other geometries\n",
    "            var geojsonFeature = {\n",
    "                \"type\": \"Feature\",\n",
    "                \"properties\": {\n",
    "                    \"rank\": index + 1,\n",
    "                    \"osmid\": item.osmid,\n",
    "                    \"demand_score\": item.demand_score,\n",
    "                    \"zip\": item.zip\n",
    "                },\n",
    "                \"geometry\": item.geometry\n",
    "            };\n",
    "            \n",
    "            L.geoJSON(geojsonFeature, {\n",
    "                style: function(feature) {\n",
    "                    return {\n",
    "                        color: '#FF4500',\n",
    "                        weight: 3,\n",
    "                        opacity: 1,\n",
    "                        fillColor: '#FF4500',\n",
    "                        fillOpacity: 0.7\n",
    "                    };\n",
    "                }\n",
    "            }).bindTooltip(function(layer) {\n",
    "                return 'Rank #' + (index + 1) + '<br>' +\n",
    "                       'ID: ' + item.osmid + '<br>' +\n",
    "                       'Demand Score: ' + item.demand_score.toFixed(2) + '<br>' +\n",
    "                       'ZIP: ' + item.zip;\n",
    "            }).addTo(highlightedGroup);\n",
    "        }\n",
    "    });\n",
    "    \n",
    "    // Show the recommendations panel\n",
    "    document.getElementById('rec-panel').style.display = 'block';\n",
    "    \n",
    "    // Update summary\n",
    "    if (topRecommendations.length === 0) {\n",
    "        document.getElementById('rec-summary').innerHTML = 'No locations found matching the criteria.';\n",
    "    } else {\n",
    "        document.getElementById('rec-summary').innerHTML = 'Showing top ' + \n",
    "            topRecommendations.length + ' recommended locations' + \n",
    "            (zip && zip.trim() !== '' ? ' in ZIP ' + zip : '') + '.';\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Insert data into JavaScript function\n",
    "js_filter_code = js_filter_code % json.dumps(js_data)\n",
    "\n",
    "# Create the filter panel HTML\n",
    "filter_html = \"\"\"\n",
    "<div style=\"position: fixed; \n",
    "     top: 10px; right: 10px; width: 300px; height: auto;\n",
    "     border:2px solid grey; z-index:9999; font-size:14px;\n",
    "     background-color: white; padding: 10px; border-radius: 5px;\">\n",
    "    <h4 style=\"margin-top: 0;\">Filter Recommendations</h4>\n",
    "    <div style=\"margin-bottom: 10px;\">\n",
    "        <label for=\"zip-input\">ZIP Code (optional):</label>\n",
    "        <input type=\"text\" id=\"zip-input\" style=\"width: 100%; padding: 5px; margin-top: 5px;\">\n",
    "    </div>\n",
    "    <div style=\"margin-bottom: 10px;\">\n",
    "        <label for=\"count-input\">Number of Recommendations:</label>\n",
    "        <input type=\"number\" id=\"count-input\" min=\"1\" max=\"50\" value=\"5\" style=\"width: 100%; padding: 5px; margin-top: 5px;\">\n",
    "    </div>\n",
    "    <button onclick=\"filterByZipAndCount(\n",
    "        document.getElementById('zip-input').value, \n",
    "        document.getElementById('count-input').value\n",
    "    )\" style=\"width: 100%; padding: 8px; background-color: #4CAF50; color: white; border: none; border-radius: 4px; cursor: pointer;\">\n",
    "        Show Recommendations\n",
    "    </button>\n",
    "    \n",
    "    <div id=\"rec-panel\" style=\"display: none; margin-top: 15px; max-height: 300px; overflow-y: auto;\">\n",
    "        <h4 style=\"margin-top: 0;\">Top Recommendations</h4>\n",
    "        <div id=\"rec-summary\" style=\"margin-bottom: 10px; font-style: italic;\"></div>\n",
    "        <div id=\"recommendations\"></div>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Add the filter panel and JavaScript to the map\n",
    "m4.get_root().html.add_child(folium.Element(filter_html))\n",
    "m4.get_root().script.add_child(folium.Element(f'<script>{js_filter_code}</script>'))\n",
    "\n",
    "# Display the map\n",
    "print(\"Interactive Parking Lot Demand Score Map with ZIP filtering and recommendation highlights\")\n",
    "m4.save(\"new.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412a68ae-7ffd-44d3-bb8f-c37f8e74dbfc",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Ensure CRS is WGS84 (EPSG:4326) for compatibility with Folium\n",
    "cs_lots_scored = merged_features.to_crs(epsg=4326)\n",
    "\n",
    "# Initialize the folium map centered on San Diego\n",
    "m3 = folium.Map(location=[32.7157, -117.1611], zoom_start=11, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Function to get coordinates based on geometry type\n",
    "def get_coords(geometry):\n",
    "    if isinstance(geometry, (Point, Polygon, MultiPolygon)):\n",
    "        centroid = geometry.centroid\n",
    "        return centroid.y, centroid.x\n",
    "    return np.nan, np.nan\n",
    "\n",
    "# Add intersection points to the map\n",
    "for _, row in cs_lots_scored.iterrows():\n",
    "    lat, lon = get_coords(row.geometry)\n",
    "    if np.isnan(lat) or np.isnan(lon):\n",
    "        continue  # Skip invalid coordinates\n",
    "\n",
    "    # Add a circle marker for each intersection\n",
    "    folium.CircleMarker(\n",
    "        location=(lat, lon),  # Latitude and Longitude\n",
    "        radius=3,\n",
    "        color=\"red\",\n",
    "        fill=True,\n",
    "        fill_opacity=0.5,\n",
    "        popup=folium.Popup(f\"Intersection OSMID: {row.osmid}<br>Zone Name: {row.zone_name}\", max_width=250),\n",
    "    ).add_to(m3)\n",
    "\n",
    "    # Add buffer zones as circles\n",
    "    folium.Circle(\n",
    "        location=(lat, lon),\n",
    "        radius=row.distance_to_nearest_charger,  # Distance in meters\n",
    "        color=\"blue\",  # Circle line color\n",
    "        weight=2,  # Line thickness\n",
    "        opacity=0.3,  # Line opacity\n",
    "        fill=True,\n",
    "        fill_opacity=0.01,  # Adjust the fill opacity separately\n",
    "    ).add_to(m3)\n",
    "\n",
    "# Display the map\n",
    "print(\"Map of parking lots with a radius to the nearest public charger\")\n",
    "m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7688d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa65ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import branca.colormap as cm\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Create filter controls\n",
    "# Get all available ZIP codes for the dropdown menu\n",
    "available_zips = sorted(merged_features['zip'].unique())\n",
    "zip_dropdown = widgets.Dropdown(\n",
    "    options=[('All ZIP Codes', None)] + [(str(z), z) for z in available_zips],\n",
    "    value=None,\n",
    "    description='ZIP Code:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Create a slider for selecting the number of recommendations\n",
    "num_recommendations = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=1,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='Number of Recommendations:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Create a button\n",
    "filter_button = widgets.Button(\n",
    "    description='Show Recommended Locations',\n",
    "    button_style='success', \n",
    "    icon='filter'\n",
    ")\n",
    "\n",
    "# Output area for displaying the map\n",
    "output = widgets.Output()\n",
    "\n",
    "def create_map_with_filter(zip_code=None, num_recommendations=5):\n",
    "    \"\"\"\n",
    "    Create a map with filtering functionality\n",
    "    \n",
    "    Parameters:\n",
    "    zip_code (str, optional): ZIP code to filter by. Default is None (no filtering).\n",
    "    num_recommendations (int, optional): Number of recommended locations. Default is 5.\n",
    "    \n",
    "    Returns:\n",
    "    folium.Map: A map with filtering and highlighted recommended locations\n",
    "    \"\"\"\n",
    "    # Ensure CRS is WGS84 (EPSG:4326)\n",
    "    features_data = merged_features.to_crs(epsg=4326)\n",
    "    \n",
    "    # Filter data if a ZIP code is provided\n",
    "    if zip_code:\n",
    "        filtered_data = features_data[features_data['zip'] == zip_code]\n",
    "    else:\n",
    "        filtered_data = features_data\n",
    "    \n",
    "    # Sort by demand score and select the top N recommendations\n",
    "    top_recommendations = filtered_data.sort_values('demand_score', ascending=False).head(num_recommendations)\n",
    "    \n",
    "    # Create a color map\n",
    "    colormap = cm.linear.YlOrRd_09.scale(features_data['demand_score'].min(), features_data['demand_score'].max())\n",
    "    \n",
    "    # Create the map\n",
    "    m = folium.Map(location=[32.7157, -117.1611], zoom_start=11, tiles='CartoDB positron')\n",
    "    \n",
    "    # Add a color legend\n",
    "    colormap.caption = \"Demand Score\"\n",
    "    colormap.add_to(m)\n",
    "    \n",
    "    # Create a layer for displaying all parking lots (initially hidden)\n",
    "    all_parking_fg = folium.FeatureGroup(name=\"All Parking Lots\", show=False)\n",
    "    \n",
    "    # Add all parking lots using the color mapping\n",
    "    for _, row in features_data.iterrows():\n",
    "        color = colormap(row['demand_score'])\n",
    "        \n",
    "        # Basic tooltip\n",
    "        tooltip = f\"ID: {row.osmid}, Score: {row.demand_score:.2f}, ZIP: {row.zip}\"\n",
    "        \n",
    "        if hasattr(row.geometry, 'y') and hasattr(row.geometry, 'x'):\n",
    "            # Point geometry\n",
    "            folium.Circle(\n",
    "                location=(row.geometry.y, row.geometry.x),\n",
    "                radius=15,\n",
    "                color=color,\n",
    "                fill=True,\n",
    "                fill_opacity=0.6,\n",
    "                tooltip=tooltip\n",
    "            ).add_to(all_parking_fg)\n",
    "        else:\n",
    "            # Try adding polygons or other geometries\n",
    "            try:\n",
    "                folium.GeoJson(\n",
    "                    row.geometry,\n",
    "                    style_function=lambda x, color=color: {\n",
    "                        'fillColor': color,\n",
    "                        'color': color,\n",
    "                        'weight': 1,\n",
    "                        'fillOpacity': 0.6\n",
    "                    },\n",
    "                    tooltip=tooltip\n",
    "                ).add_to(all_parking_fg)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    \n",
    "    # Create a layer to highlight recommended locations (default: visible)\n",
    "    recommendations_fg = folium.FeatureGroup(name=\"Recommended Parking Lots\", show=True)\n",
    "    \n",
    "    # Add recommended locations using a prominent orange-red color\n",
    "    for i, (_, row) in enumerate(top_recommendations.iterrows()):\n",
    "        # Detailed tooltip including ranking\n",
    "        tooltip = (\n",
    "            f\"Rank #{i+1}<br>\"\n",
    "            f\"ID: {row.osmid}<br>\"\n",
    "            f\"Demand Score: {row.demand_score:.2f}<br>\"\n",
    "            f\"ZIP: {row.zip}<br>\"\n",
    "            f\"Zone Type: {row.zone_type}\"\n",
    "        )\n",
    "        \n",
    "        if hasattr(row.geometry, 'y') and hasattr(row.geometry, 'x'):\n",
    "            # Point geometry\n",
    "            folium.Circle(\n",
    "                location=(row.geometry.y, row.geometry.x),\n",
    "                radius=25,\n",
    "                color='#FF4500',\n",
    "                weight=3,\n",
    "                fill=True,\n",
    "                fill_opacity=0.7,\n",
    "                tooltip=tooltip\n",
    "            ).add_to(recommendations_fg)\n",
    "        else:\n",
    "            # Try adding polygons or other geometries\n",
    "            try:\n",
    "                folium.GeoJson(\n",
    "                    row.geometry,\n",
    "                    style_function=lambda x: {\n",
    "                        'fillColor': '#FF4500',\n",
    "                        'color': '#FF4500',\n",
    "                        'weight': 3,\n",
    "                        'fillOpacity': 0.7\n",
    "                    },\n",
    "                    tooltip=tooltip\n",
    "                ).add_to(recommendations_fg)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    \n",
    "    # Add layers to the map\n",
    "    all_parking_fg.add_to(m)\n",
    "    recommendations_fg.add_to(m)\n",
    "    \n",
    "    # Add a layer control and keep it expanded\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "    \n",
    "    # Add title and description\n",
    "    title_html = f'''\n",
    "    <div style=\"position: fixed; \n",
    "         top: 10px; left: 100px; width: 600px; height: auto;\n",
    "         font-size:20px; font-family: 'Arial'; z-index:9999; \n",
    "         background-color: white; padding: 10px; border-radius: 5px; border:2px solid grey;\n",
    "         text-align: center;\">\n",
    "         <b>Parking Lot Demand Score Map</b><br>\n",
    "         <span style=\"font-size:14px;\">\n",
    "         {f'Showing top {len(top_recommendations)} recommendations in ZIP code {zip_code}' \n",
    "         if zip_code else f'Showing top {len(top_recommendations)} recommendations across all ZIP codes'}\n",
    "         </span>\n",
    "    </div>\n",
    "    '''\n",
    "    m.get_root().html.add_child(folium.Element(title_html))\n",
    "    \n",
    "    # Add a results list to the map\n",
    "    results_html = f'''\n",
    "    <div style=\"position: fixed; \n",
    "         bottom: 10px; right: 10px; width: 300px; max-height: 300px;\n",
    "         font-size:12px; font-family: 'Arial'; z-index:9999; \n",
    "         background-color: white; padding: 10px; border-radius: 5px; border:2px solid grey;\n",
    "         overflow-y: auto;\">\n",
    "         <b>Top {len(top_recommendations)} Recommendations:</b><br>\n",
    "    '''\n",
    "    \n",
    "    for i, (_, row) in enumerate(top_recommendations.iterrows()):\n",
    "        results_html += f'''\n",
    "        <div style=\"margin: 5px 0; padding: 5px; border-bottom: 1px solid #eee;\">\n",
    "            <b>#{i+1}:</b> ID: {row.osmid}<br>\n",
    "            Score: {row.demand_score:.2f}<br>\n",
    "            ZIP: {row.zip}<br>\n",
    "            Zone: {row.zone_type if 'zone_type' in row else 'N/A'}\n",
    "        </div>\n",
    "        '''\n",
    "    \n",
    "    results_html += '</div>'\n",
    "    m.get_root().html.add_child(folium.Element(results_html))\n",
    "    \n",
    "    # Return the map\n",
    "    return m\n",
    "\n",
    "# Callback function when the button is clicked\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print(f\"Creating map... ZIP Code: {'All' if zip_dropdown.value is None else zip_dropdown.value}, Number of Recommendations: {num_recommendations.value}\")\n",
    "        m = create_map_with_filter(zip_code=zip_dropdown.value, num_recommendations=num_recommendations.value)\n",
    "        display(m)\n",
    "\n",
    "# Bind the callback function to the button\n",
    "filter_button.on_click(on_button_clicked)\n",
    "\n",
    "# Layout controls\n",
    "controls = widgets.VBox([\n",
    "    widgets.HBox([zip_dropdown, num_recommendations]), \n",
    "    filter_button\n",
    "])\n",
    "\n",
    "# Display controls and output area\n",
    "display(HTML(\"<h3>Charging Station Demand Score Map - Interactive Filtering</h3>\"))\n",
    "display(controls)\n",
    "display(output)\n",
    "\n",
    "# Load the initial map\n",
    "with output:\n",
    "    print(\"Creating initial map...\")\n",
    "    m = create_map_with_filter()\n",
    "    display(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6017bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster, MeasureControl\n",
    "import branca.colormap as cm\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "\n",
    "# Create a base map centered on San Diego using the cartodbpositron tile layer\n",
    "combined_map = folium.Map(location=[32.7157, -117.1611], zoom_start=12, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Modify area color mapping with more saturated colors\n",
    "color_mapping = {\n",
    "    'Commercial': '#4A90E2',       # Brighter blue\n",
    "    'Office': '#50C878',           # Emerald green\n",
    "    'Residential High': '#E74C3C', # Bright red\n",
    "    'Residential Medium': '#F4D03F', # Golden yellow\n",
    "    'Residential Low': '#F9E79F',  # Light yellow\n",
    "    'Residential Mixed': '#FF69B4', # Bright pink\n",
    "    'Industrial': '#95A5A6',       # Silver gray\n",
    "    'Mixed Use': '#2CCBCB',        # Blue-green\n",
    "    'Agricultural': '#DAA520',     # Goldenrod\n",
    "    'Open Space': '#87CEFA',       # Light blue\n",
    "    'Planned': '#00CED1',          # Teal\n",
    "    'Transit': '#9370DB',          # Medium purple\n",
    "    'Other': '#5D6D7E',            # Dark gray\n",
    "    'Multiple': '#9932CC'          # Dark orchid\n",
    "}\n",
    "\n",
    "# Function: Style for zoning polygons\n",
    "def zoning_style(feature):\n",
    "    zone_type = feature['properties']['zone_type']\n",
    "    color = color_mapping.get(zone_type, 'gray')  # Default to gray if not found\n",
    "    return {\n",
    "        'fillColor': color, \n",
    "        'color': 'black', \n",
    "        'weight': 1,\n",
    "        'fillOpacity': 0.3,\n",
    "    }\n",
    "\n",
    "# Function: Get coordinates from geometry\n",
    "def get_coords(geometry):\n",
    "    if isinstance(geometry, (Point, Polygon, MultiPolygon)):\n",
    "        centroid = geometry.centroid\n",
    "        return centroid.y, centroid.x\n",
    "    return np.nan, np.nan\n",
    "\n",
    "# Create layer groups for toggling their visibility\n",
    "zoning_layer = folium.FeatureGroup(name='Zoning Areas')\n",
    "parking_layer = folium.FeatureGroup(name='Public Parking Lots')\n",
    "zoned_parking_layer = folium.FeatureGroup(name='Parking by Zone Type')\n",
    "charger_distance_layer = folium.FeatureGroup(name='Distance to Nearest Charger')\n",
    "\n",
    "# 1. Add zoning layer (GeoJSON file containing area polygons)\n",
    "folium.GeoJson(\n",
    "    zoning_data,  # GeoJSON file containing area polygons\n",
    "    style_function=zoning_style,\n",
    "    name='Zoning Areas'\n",
    ").add_to(zoning_layer)\n",
    "\n",
    "# 2. Add original parking data (from the first map)\n",
    "for _, row in public_parking_gdf.iterrows():\n",
    "    if row.geometry.geom_type == \"Point\":\n",
    "        folium.CircleMarker(\n",
    "            location=[row.geometry.y, row.geometry.x],\n",
    "            radius=5,\n",
    "            color=\"#004080\",  # Dark blue border\n",
    "            fill=True,\n",
    "            fill_color=\"#0066CC\",  # More saturated blue fill\n",
    "            fill_opacity=0.8,  # Increase opacity\n",
    "            weight=2,  # Thicker border\n",
    "            tooltip=\"Public Parking Lot\",\n",
    "            popup=folium.Popup(f\"Public Parking Lot<br>Type: {row.get('parking', 'Unknown')}\", max_width=250),\n",
    "        ).add_to(parking_layer)\n",
    "    elif row.geometry.geom_type in [\"Polygon\", \"MultiPolygon\"]:\n",
    "        folium.GeoJson(\n",
    "            row.geometry,\n",
    "            style_function=lambda x: {\n",
    "                \"color\": \"#004080\",  # Dark blue border\n",
    "                \"fillColor\": \"#0066CC\",  # More saturated blue fill\n",
    "                \"weight\": 2,  # Thicker border\n",
    "                \"fillOpacity\": 0.6,  # Increase opacity\n",
    "            },\n",
    "            tooltip=\"Non-Private Parking Lot\"\n",
    "        ).add_to(parking_layer)\n",
    "\n",
    "# 3. Add parking data with zone type information (from the second map)\n",
    "for _, row in lots.iterrows():\n",
    "    zone_type = row['zone_type'] if 'zone_type' in row else \"Unknown\"\n",
    "    # Get zone color with increased saturation\n",
    "    zone_color = color_mapping.get(zone_type, 'gray')\n",
    "    \n",
    "    if row.geometry.geom_type == \"Point\":\n",
    "        folium.CircleMarker(\n",
    "            location=[row.geometry.y, row.geometry.x],\n",
    "            radius=5,\n",
    "            color=zone_color,  # Use the original color mapping\n",
    "            fill=True,\n",
    "            fill_color=zone_color,\n",
    "            fill_opacity=0.9,  # Increase opacity\n",
    "            weight=2,  # Increase border thickness\n",
    "            tooltip=f\"Zone: {zone_type}\",\n",
    "            popup=folium.Popup(f\"Zone Type: {zone_type}<br>OSMID: {row.get('osmid', 'N/A')}\", max_width=250),\n",
    "        ).add_to(zoned_parking_layer)\n",
    "    elif row.geometry.geom_type in [\"Polygon\", \"MultiPolygon\"]:\n",
    "        folium.GeoJson(\n",
    "            row.geometry,\n",
    "            style_function=lambda x: {\"color\": zone_color, \"fillColor\": zone_color, \"weight\": 1, \"fillOpacity\": 0.4},\n",
    "            tooltip=f\"Zone: {zone_type}\"\n",
    "        ).add_to(zoned_parking_layer)\n",
    "\n",
    "# 4. Add charger distance information layer (from the third map)\n",
    "for _, row in merged_features.iterrows():\n",
    "    lat, lon = get_coords(row.geometry)\n",
    "    if np.isnan(lat) or np.isnan(lon):\n",
    "        continue  # Skip invalid coordinates\n",
    "    \n",
    "    # Add a circular marker for each intersection with increased radius for easier clicking\n",
    "    folium.CircleMarker(\n",
    "        location=(lat, lon),  # Latitude and longitude\n",
    "        radius=5,  # Increase radius for easier clicking\n",
    "        color=\"red\",\n",
    "        fill=True,\n",
    "        fill_color=\"red\",\n",
    "        fill_opacity=0.7,\n",
    "        weight=2,  # Increase border thickness\n",
    "        tooltip=f\"OSMID: {row.osmid} (Click for details)\",\n",
    "        popup=folium.Popup(f\"<b>Charging Station Data</b><br>OSMID: {row.osmid}<br>Zone Name: {row.zone_name}<br>Distance to Charger: {row.distance_to_nearest_charger:.1f}m\", max_width=300),\n",
    "    ).add_to(charger_distance_layer)\n",
    "    \n",
    "    # Add a circular buffer\n",
    "    folium.Circle(\n",
    "        location=(lat, lon),\n",
    "        radius=row.distance_to_nearest_charger,  # Distance in meters\n",
    "        color=\"blue\",  # Circle line color\n",
    "        weight=2,  # Line thickness\n",
    "        opacity=0.3,  # Line opacity\n",
    "        fill=True,\n",
    "        fill_opacity=0.01,  # Adjust fill opacity separately\n",
    "    ).add_to(charger_distance_layer)\n",
    "\n",
    "# 5. Add zoning legend\n",
    "opacity = 0.8\n",
    "legend_html = f\"\"\"\n",
    "<div style=\"position: fixed; \n",
    "             top: 10px; left: 10px; \n",
    "             width: 200px; height: auto; \n",
    "             background-color: rgba(255, 255, 255, {opacity}); \n",
    "             border:2px solid grey; \n",
    "             z-index: 9999; \n",
    "             font-size:14px;\n",
    "             padding: 10px;\">\n",
    "    <b>Zoning Categories</b><br>\n",
    "    <div style=\"line-height: 1.5;\">\n",
    "\"\"\"\n",
    "for category, color in color_mapping.items():\n",
    "    legend_html += f'<div><i style=\"background:{color}; width: 20px; height: 20px; display: inline-block;\"></i> {category}</div>'\n",
    "legend_html += \"</div></div>\"\n",
    "combined_map.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "# 6. Add second legend for the charger distance layer\n",
    "charger_legend_html = f\"\"\"\n",
    "<div style=\"position: fixed; \n",
    "             bottom: 10px; right: 10px; \n",
    "             width: 220px; height: auto; \n",
    "             background-color: rgba(255, 255, 255, {opacity}); \n",
    "             border:2px solid grey; \n",
    "             z-index: 9999; \n",
    "             font-size:14px;\n",
    "             padding: 10px;\">\n",
    "    <b>Charger Distance Layer</b><br>\n",
    "    <div style=\"line-height: 1.5;\">\n",
    "    <div><i style=\"background:red; width: 10px; height: 10px; border-radius: 50%; display: inline-block;\"></i> Parking Spot</div>\n",
    "    <div><i style=\"border: 2px solid blue; width: 16px; height: 16px; border-radius: 50%; display: inline-block;\"></i> Distance to Nearest Charger</div>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "combined_map.get_root().html.add_child(folium.Element(charger_legend_html))\n",
    "\n",
    "# Modify the order of adding layers to ensure the most important information is on top\n",
    "# Layer order from bottom to top: 1. Zoning Areas -> 2. Public Parking Lots -> 3. Parking by Zone Type -> 4. Charger Distance\n",
    "\n",
    "# 1. First, add the bottom layer - Zoning Areas\n",
    "zoning_layer.add_to(combined_map)\n",
    "\n",
    "# 2. Add middle layers - Public Parking Lots and Parking by Zone Type\n",
    "parking_layer.add_to(combined_map)\n",
    "zoned_parking_layer.add_to(combined_map)\n",
    "\n",
    "# 3. Finally, add the top layer - Charger Distance information\n",
    "charger_distance_layer.add_to(combined_map)\n",
    "\n",
    "# 6. Create a custom layer control function to ensure proper click behavior\n",
    "def create_custom_layer_control():\n",
    "    custom_layer_control = '''\n",
    "    <script>\n",
    "    document.addEventListener(\"DOMContentLoaded\", function() {\n",
    "        // Wait for the map to finish loading\n",
    "        setTimeout(function() {\n",
    "            // Add additional click handling for the layer control\n",
    "            var checkboxes = document.querySelectorAll('.leaflet-control-layers-overlays input[type=\"checkbox\"]');\n",
    "            \n",
    "            if (checkboxes.length >= 4) {\n",
    "                // By default, turn off some layers\n",
    "                checkboxes[1].click(); // Turn off Public Parking Lot layer\n",
    "                checkboxes[2].click(); // Turn off Zoned Parking Lot layer\n",
    "                \n",
    "                // Add click event handling\n",
    "                checkboxes.forEach(function(checkbox, index) {\n",
    "                    checkbox.addEventListener('change', function() {\n",
    "                        // Record the current layer state\n",
    "                        console.log(\"Layer \" + index + \" is now: \" + (this.checked ? \"on\" : \"off\"));\n",
    "                        \n",
    "                        // If the user opens multiple conflicting layers, show a tip\n",
    "                        var enabledLayers = Array.from(checkboxes).filter(cb => cb.checked).length;\n",
    "                        if (enabledLayers > 2) {\n",
    "                            // Create or update the tip element\n",
    "                            var tipElement = document.getElementById('map-layer-tip');\n",
    "                            if (!tipElement) {\n",
    "                                tipElement = document.createElement('div');\n",
    "                                tipElement.id = 'map-layer-tip';\n",
    "                                tipElement.style.position = 'fixed';\n",
    "                                tipElement.style.bottom = '40px';\n",
    "                                tipElement.style.left = '50%';\n",
    "                                tipElement.style.transform = 'translateX(-50%)';\n",
    "                                tipElement.style.backgroundColor = 'rgba(0, 0, 0, 0.7)';\n",
    "                                tipElement.style.color = 'white';\n",
    "                                tipElement.style.padding = '8px 12px';\n",
    "                                tipElement.style.borderRadius = '4px';\n",
    "                                tipElement.style.fontSize = '14px';\n",
    "                                tipElement.style.zIndex = '1000';\n",
    "                                document.body.appendChild(tipElement);\n",
    "                            }\n",
    "                            \n",
    "                            tipElement.textContent = 'Tip: Opening multiple layers at the same time may cause click conflicts. It is recommended to view layers one at a time.';\n",
    "                            tipElement.style.display = 'block';\n",
    "                            \n",
    "                            // Hide the tip after 3 seconds\n",
    "                            setTimeout(function() {\n",
    "                                tipElement.style.display = 'none';\n",
    "                            }, 3000);\n",
    "                        }\n",
    "                    });\n",
    "                });\n",
    "            }\n",
    "        }, 1000);\n",
    "    });\n",
    "    </script>\n",
    "    '''\n",
    "    return custom_layer_control\n",
    "\n",
    "# Add custom layer control\n",
    "combined_map.get_root().html.add_child(folium.Element(create_custom_layer_control()))\n",
    "\n",
    "# 8. Add layer control (positioned at the top right and initially collapsed to reduce clutter)\n",
    "folium.LayerControl(position='topright', collapsed=True).add_to(combined_map)\n",
    "\n",
    "# Add a small scale\n",
    "MeasureControl(position='bottomleft', primary_length_unit='meters').add_to(combined_map)\n",
    "\n",
    "# Save the map as an HTML file\n",
    "combined_map.save(\"combined_parking_zoning_charger_map.html\")\n",
    "\n",
    "# Display the map\n",
    "print(\"Combined Map of Parking Lots, City Zoning, and Distance to Nearest Chargers\")\n",
    "combined_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b986b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4.save(\"final_result_map.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d8bfa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6038dbf-6925-456e-b24d-e4784b00660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# type_cols = ['ev_dc_fast_num','ev_level1_evse_num','ev_level2_evse_num']\n",
    "\n",
    "# cs_by_intersection = cs_gdf.groupby('osmid')[type_cols+connector_cols].sum().reset_index()\n",
    "# intersection_cs = intersections.merge(cs_by_intersection, how='left', on='osmid')\n",
    "\n",
    "# intersection_cs[type_cols] = intersection_cs[type_cols].fillna(0)\n",
    "# intersection_cs[connector_cols] = intersection_cs[connector_cols].fillna(0)\n",
    "# intersection_cs['cs_total'] = intersection_cs[type_cols].sum(axis=1)\n",
    "\n",
    "# intersection_cs[connector_cols] = intersection_cs[connector_cols] > 0\n",
    "\n",
    "# print(intersection_cs.shape)\n",
    "# intersection_cs.sort_values(by='cs_total', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16775668-a2aa-4ee4-8365-e35e923285c5",
   "metadata": {},
   "source": [
    "### DMV Registration Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed97217-ba1f-4ee8-a24f-8136e3bbdd3e",
   "metadata": {},
   "source": [
    "Now filter the charger data to get all public AFDC chargers in the SDG&E territory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86f743d-060e-45de-8a3f-6f37acec45b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DMV\n",
    "# dmv = dmv_data.copy()\n",
    "# dmv = dmv[dmv['ZIP Code']!=\"OOS\"]\n",
    "# dmv['ZIP Code'] = dmv['ZIP Code'].astype(int)\n",
    "# dmv = dmv[dmv['ZIP Code'].isin(sdge_zips)]\n",
    "# print(dmv.shape)\n",
    "# dmv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782689c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score, \n",
    "                             precision_recall_curve, auc, f1_score, make_scorer,\n",
    "                             precision_score, recall_score, average_precision_score)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# For handling imbalanced data\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, EasyEnsembleClassifier, BalancedBaggingClassifier\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "# Models to compare\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "except ImportError:\n",
    "    print(\"XGBoost not available, skipping XGBoost models\")\n",
    "    XGBClassifier = None\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "except ImportError:\n",
    "    print(\"LightGBM not available, skipping LightGBM models\")\n",
    "    LGBMClassifier = None\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('features.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Check target distribution\n",
    "print(f\"Target distribution:\\n{df['has_charger'].value_counts()}\")\n",
    "print(f\"Percentage of chargers: {df['has_charger'].mean() * 100:.2f}%\")\n",
    "\n",
    "# Remove geometry column as it's not usable for ML\n",
    "if 'geometry' in df.columns:\n",
    "    df = df.drop('geometry', axis=1)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"\\nFeatures with missing values:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Separate categorical and numerical features\n",
    "categorical_cols = ['amenity', 'access', 'fee', 'parking', 'zone_name', 'zone_type']\n",
    "numerical_cols = [col for col in df.columns if col not in categorical_cols + ['has_charger', 'osmid', 'geometry']]\n",
    "\n",
    "# Prepare data for modeling\n",
    "X = df.drop(['has_charger', 'osmid'] + [col for col in categorical_cols if col in df.columns], axis=1)\n",
    "y = df['has_charger']\n",
    "\n",
    "# Feature selection based on our previous correlation analysis\n",
    "important_features = ['percentile_chargers_in_radius', 'percentile_distance_to_nearest_charger', \n",
    "                     'distance_to_nearest_charger', 'percentile_cs_total', 'traffic',\n",
    "                     'cs_total', 'Population', 'Median Income', 'zoning_score', \n",
    "                     'chargers_in_radius', 'demand_score', 'income_score', 'population_score']\n",
    "\n",
    "# Select only important features\n",
    "X = X[important_features]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"\\nTraining set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "print(f\"Training class distribution: {pd.Series(y_train).value_counts()}\")\n",
    "print(f\"Testing class distribution: {pd.Series(y_test).value_counts()}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Feature Importance Visualization\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Calculate feature correlation with target\n",
    "correlations = {}\n",
    "for col in X.columns:\n",
    "    correlations[col] = np.corrcoef(X[col].values, y.values)[0, 1]\n",
    "\n",
    "correlation_series = pd.Series(correlations).abs().sort_values(ascending=False)\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_series.plot(kind='bar')\n",
    "plt.title('Feature Correlation with Target')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_correlation.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nFeature correlation with target:\")\n",
    "print(correlation_series)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Imbalanced Data Handling and Model Evaluation Functions\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def evaluate_model(y_true, y_pred, y_prob=None):\n",
    "    \"\"\"Evaluate model performance for imbalanced classification.\"\"\"\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate precision, recall, F1 score for positive class\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate ROC AUC if probabilities are provided\n",
    "    roc_auc = None\n",
    "    pr_auc = None\n",
    "    if y_prob is not None:\n",
    "        roc_auc = roc_auc_score(y_true, y_prob)\n",
    "        precision_curve, recall_curve, _ = precision_recall_curve(y_true, y_prob)\n",
    "        pr_auc = auc(recall_curve, precision_curve)\n",
    "    \n",
    "    # Calculate G-mean\n",
    "    g_mean = geometric_mean_score(y_true, y_pred)\n",
    "    \n",
    "    results = {\n",
    "        'confusion_matrix': cm,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'g_mean': g_mean,\n",
    "        'roc_auc': roc_auc,\n",
    "        'pr_auc': pr_auc\n",
    "    }\n",
    "    \n",
    "    return report, results\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion Matrix', filename='confusion_matrix.png'):\n",
    "    \"\"\"Plot confusion matrix.\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "def plot_roc_curve(y_true, y_prob, title='ROC Curve', filename='roc_curve.png'):\n",
    "    \"\"\"Plot ROC curve.\"\"\"\n",
    "    from sklearn.metrics import roc_curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "def plot_precision_recall_curve(y_true, y_prob, title='Precision-Recall Curve', filename='pr_curve.png'):\n",
    "    \"\"\"Plot Precision-Recall curve.\"\"\"\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, color='darkorange', lw=2, label=f'PR curve (area = {pr_auc:.2f})')\n",
    "    plt.axhline(y=sum(y_true)/len(y_true), color='navy', linestyle='--', label='No Skill')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# First set of models: Baseline models without handling class imbalance\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def run_baseline_models():\n",
    "    \"\"\"Run baseline models without handling class imbalance.\"\"\"\n",
    "    print(\"\\n\\n------ BASELINE MODELS (WITHOUT IMBALANCE HANDLING) ------\\n\")\n",
    "    \n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "        'Random Forest': RandomForestClassifier(random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "        'SVM': SVC(probability=True, random_state=42),\n",
    "        'KNN': KNeighborsClassifier(),\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "        'Naive Bayes': GaussianNB()\n",
    "    }\n",
    "    \n",
    "    if XGBClassifier:\n",
    "        models['XGBoost'] = XGBClassifier(random_state=42)\n",
    "    \n",
    "    if LGBMClassifier:\n",
    "        models['LightGBM'] = LGBMClassifier(random_state=42)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        # Create a pipeline with preprocessing\n",
    "        pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        # Train the model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        y_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Evaluate the model\n",
    "        report, metrics = evaluate_model(y_test, y_pred, y_prob)\n",
    "        \n",
    "        print(f\"\\n{name} Results:\")\n",
    "        print(report)\n",
    "        print(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\n",
    "        print(f\"PR AUC: {metrics['pr_auc']:.4f}\")\n",
    "        print(f\"G-mean: {metrics['g_mean']:.4f}\")\n",
    "        \n",
    "        results[name] = metrics\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plot_confusion_matrix(metrics['confusion_matrix'], \n",
    "                             title=f'{name} Confusion Matrix',\n",
    "                             filename=f'{name.lower().replace(\" \", \"_\")}_cm.png')\n",
    "        \n",
    "        # Plot ROC curve\n",
    "        plot_roc_curve(y_test, y_prob, \n",
    "                      title=f'{name} ROC Curve', \n",
    "                      filename=f'{name.lower().replace(\" \", \"_\")}_roc.png')\n",
    "        \n",
    "        # Plot Precision-Recall curve\n",
    "        plot_precision_recall_curve(y_test, y_prob,\n",
    "                                  title=f'{name} Precision-Recall Curve',\n",
    "                                  filename=f'{name.lower().replace(\" \", \"_\")}_pr.png')\n",
    "    \n",
    "    return results\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Second set of models: Models with resampling methods for imbalanced data\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def run_resampling_models():\n",
    "    \"\"\"Run models with resampling methods for imbalanced data.\"\"\"\n",
    "    print(\"\\n\\n------ MODELS WITH RESAMPLING METHODS ------\\n\")\n",
    "    \n",
    "    base_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    \n",
    "    resampling_methods = {\n",
    "        'SMOTE': SMOTE(random_state=42),\n",
    "        'ADASYN': ADASYN(random_state=42),\n",
    "        'RandomUnderSampler': RandomUnderSampler(random_state=42),\n",
    "        'TomekLinks': TomekLinks(),\n",
    "        'SMOTE + ENN': SMOTEENN(random_state=42),\n",
    "        'SMOTE + Tomek': SMOTETomek(random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, resampler in resampling_methods.items():\n",
    "        print(f\"\\nTraining with {name}...\")\n",
    "        \n",
    "        # Create a pipeline with preprocessing and resampling\n",
    "        pipeline = ImbPipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('resampler', resampler),\n",
    "            ('model', base_model)\n",
    "        ])\n",
    "        \n",
    "        # Train the model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        y_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Evaluate the model\n",
    "        report, metrics = evaluate_model(y_test, y_pred, y_prob)\n",
    "        \n",
    "        print(f\"\\nLogistic Regression with {name} Results:\")\n",
    "        print(report)\n",
    "        print(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\n",
    "        print(f\"PR AUC: {metrics['pr_auc']:.4f}\")\n",
    "        print(f\"G-mean: {metrics['g_mean']:.4f}\")\n",
    "        \n",
    "        results[name] = metrics\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plot_confusion_matrix(metrics['confusion_matrix'], \n",
    "                             title=f'LR with {name} Confusion Matrix',\n",
    "                             filename=f'lr_{name.lower().replace(\" \", \"_\").replace(\"+\", \"plus\")}_cm.png')\n",
    "        \n",
    "        # Plot ROC curve\n",
    "        plot_roc_curve(y_test, y_prob, \n",
    "                      title=f'LR with {name} ROC Curve', \n",
    "                      filename=f'lr_{name.lower().replace(\" \", \"_\").replace(\"+\", \"plus\")}_roc.png')\n",
    "        \n",
    "        # Plot Precision-Recall curve\n",
    "        plot_precision_recall_curve(y_test, y_prob,\n",
    "                                  title=f'LR with {name} Precision-Recall Curve',\n",
    "                                  filename=f'lr_{name.lower().replace(\" \", \"_\").replace(\"+\", \"plus\")}_pr.png')\n",
    "    \n",
    "    return results\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Third set of models: Specialized algorithms for imbalanced data\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def run_specialized_models():\n",
    "    \"\"\"Run specialized algorithms for imbalanced data.\"\"\"\n",
    "    print(\"\\n\\n------ SPECIALIZED ALGORITHMS FOR IMBALANCED DATA ------\\n\")\n",
    "    \n",
    "    models = {\n",
    "        'BalancedRandomForest': BalancedRandomForestClassifier(random_state=42),\n",
    "        'EasyEnsemble': EasyEnsembleClassifier(random_state=42),\n",
    "        'BalancedBagging': BalancedBaggingClassifier(random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        \n",
    "        # Create a pipeline with preprocessing\n",
    "        pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        # Train the model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        y_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Evaluate the model\n",
    "        report, metrics = evaluate_model(y_test, y_pred, y_prob)\n",
    "        \n",
    "        print(f\"\\n{name} Results:\")\n",
    "        print(report)\n",
    "        print(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\n",
    "        print(f\"PR AUC: {metrics['pr_auc']:.4f}\")\n",
    "        print(f\"G-mean: {metrics['g_mean']:.4f}\")\n",
    "        \n",
    "        results[name] = metrics\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plot_confusion_matrix(metrics['confusion_matrix'], \n",
    "                             title=f'{name} Confusion Matrix',\n",
    "                             filename=f'{name.lower()}_cm.png')\n",
    "        \n",
    "        # Plot ROC curve\n",
    "        plot_roc_curve(y_test, y_prob, \n",
    "                      title=f'{name} ROC Curve', \n",
    "                      filename=f'{name.lower()}_roc.png')\n",
    "        \n",
    "        # Plot Precision-Recall curve\n",
    "        plot_precision_recall_curve(y_test, y_prob,\n",
    "                                  title=f'{name} Precision-Recall Curve',\n",
    "                                  filename=f'{name.lower()}_pr.png')\n",
    "    \n",
    "    return results\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Fourth set: Cost-sensitive learning and threshold tuning\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def run_cost_sensitive_learning():\n",
    "    \"\"\"Run cost-sensitive learning approaches.\"\"\"\n",
    "    print(\"\\n\\n------ COST-SENSITIVE LEARNING ------\\n\")\n",
    "    \n",
    "    # Define different class weights\n",
    "    class_weights = {\n",
    "        'balanced': 'balanced',\n",
    "        'custom_1': {0: 1, 1: 10},\n",
    "        'custom_2': {0: 1, 1: 20},\n",
    "        'custom_3': {0: 1, 1: 50}\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for weight_name, class_weight in class_weights.items():\n",
    "        print(f\"\\nTraining with class weight: {weight_name}...\")\n",
    "        \n",
    "        # Create a model with specified class weights\n",
    "        model = LogisticRegression(class_weight=class_weight, max_iter=1000, random_state=42)\n",
    "        \n",
    "        # Create a pipeline with preprocessing\n",
    "        pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        # Train the model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        y_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Evaluate the model\n",
    "        report, metrics = evaluate_model(y_test, y_pred, y_prob)\n",
    "        \n",
    "        print(f\"\\nLogistic Regression with {weight_name} class weight Results:\")\n",
    "        print(report)\n",
    "        print(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\n",
    "        print(f\"PR AUC: {metrics['pr_auc']:.4f}\")\n",
    "        print(f\"G-mean: {metrics['g_mean']:.4f}\")\n",
    "        \n",
    "        results[weight_name] = metrics\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plot_confusion_matrix(metrics['confusion_matrix'], \n",
    "                             title=f'LR with {weight_name} class weight Confusion Matrix',\n",
    "                             filename=f'lr_{weight_name}_cm.png')\n",
    "        \n",
    "    return results\n",
    "\n",
    "def threshold_tuning():\n",
    "    \"\"\"Perform threshold tuning for improved performance.\"\"\"\n",
    "    print(\"\\n\\n------ THRESHOLD TUNING ------\\n\")\n",
    "    \n",
    "    # Use the best model from previous experiments (can be adjusted based on results)\n",
    "    model = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "    \n",
    "    # Create a pipeline with preprocessing\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Get probability predictions\n",
    "    y_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Test different thresholds\n",
    "    thresholds = np.arange(0.1, 0.9, 0.1)\n",
    "    results = {}\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        # Apply threshold\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        report, metrics = evaluate_model(y_test, y_pred, y_prob)\n",
    "        \n",
    "        print(f\"\\nThreshold = {threshold:.1f} Results:\")\n",
    "        print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "        print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "        print(f\"F1-score: {metrics['f1_score']:.4f}\")\n",
    "        print(f\"G-mean: {metrics['g_mean']:.4f}\")\n",
    "        \n",
    "        results[threshold] = metrics\n",
    "    \n",
    "    # Visualize threshold impact\n",
    "    thresholds_list = list(results.keys())\n",
    "    precision_list = [results[t]['precision'] for t in thresholds_list]\n",
    "    recall_list = [results[t]['recall'] for t in thresholds_list]\n",
    "    f1_list = [results[t]['f1_score'] for t in thresholds_list]\n",
    "    g_mean_list = [results[t]['g_mean'] for t in thresholds_list]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(thresholds_list, precision_list, 'bo-', label='Precision')\n",
    "    plt.plot(thresholds_list, recall_list, 'ro-', label='Recall')\n",
    "    plt.plot(thresholds_list, f1_list, 'go-', label='F1-score')\n",
    "    plt.plot(thresholds_list, g_mean_list, 'mo-', label='G-mean')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Impact of Threshold on Classification Metrics')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig('threshold_tuning.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Fifth set: Hyperparameter tuning for best models\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def hyperparameter_tuning():\n",
    "    \"\"\"Perform hyperparameter tuning for the best models.\"\"\"\n",
    "    print(\"\\n\\n------ HYPERPARAMETER TUNING ------\\n\")\n",
    "    \n",
    "    # Choose the best resampling method based on previous results (adjust as needed)\n",
    "    resampler = SMOTE(random_state=42)\n",
    "    \n",
    "    # Models to tune\n",
    "    models = {\n",
    "        'Logistic Regression': {\n",
    "            'model': LogisticRegression(random_state=42, max_iter=1000),\n",
    "            'params': {\n",
    "                'model__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                'model__penalty': ['l1', 'l2'],\n",
    "                'model__solver': ['liblinear', 'saga'],\n",
    "                'model__class_weight': ['balanced', {0: 1, 1: 10}, {0: 1, 1: 20}]\n",
    "            }\n",
    "        },\n",
    "        'Random Forest': {\n",
    "            'model': RandomForestClassifier(random_state=42),\n",
    "            'params': {\n",
    "                'model__n_estimators': [50, 100, 200],\n",
    "                'model__max_depth': [None, 5, 10, 20],\n",
    "                'model__min_samples_split': [2, 5, 10],\n",
    "                'model__class_weight': ['balanced', 'balanced_subsample', None]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if XGBClassifier:\n",
    "        models['XGBoost'] = {\n",
    "            'model': XGBClassifier(random_state=42),\n",
    "            'params': {\n",
    "                'model__n_estimators': [50, 100, 200],\n",
    "                'model__max_depth': [3, 5, 7],\n",
    "                'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "                'model__scale_pos_weight': [1, 5, 10, 20]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, config in models.items():\n",
    "        print(f\"\\nTuning {name}...\")\n",
    "        \n",
    "        # Create a pipeline with preprocessing and resampling\n",
    "        pipeline = ImbPipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('resampler', resampler),\n",
    "            ('model', config['model'])\n",
    "        ])\n",
    "        \n",
    "        # Define scoring metrics\n",
    "        scoring = {\n",
    "            'precision': 'precision',\n",
    "            'recall': 'recall',\n",
    "            'f1': 'f1',\n",
    "            'roc_auc': 'roc_auc'\n",
    "        }\n",
    "        \n",
    "        # Define cross-validation strategy\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # Create grid search\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            config['params'],\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            refit='f1',  # Optimize for F1 score\n",
    "            verbose=1,\n",
    "            n_jobs=-1  # Use all available cores\n",
    "        )\n",
    "        \n",
    "        # Fit grid search\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Get best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Evaluate the model\n",
    "        report, metrics = evaluate_model(y_test, y_pred, y_prob)\n",
    "        \n",
    "        print(f\"\\n{name} Best Parameters:\")\n",
    "        print(grid_search.best_params_)\n",
    "        print(f\"\\n{name} Results:\")\n",
    "        print(report)\n",
    "        print(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\n",
    "        print(f\"PR AUC: {metrics['pr_auc']:.4f}\")\n",
    "        print(f\"G-mean: {metrics['g_mean']:.4f}\")\n",
    "        \n",
    "        results[name] = {\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'metrics': metrics\n",
    "        }\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plot_confusion_matrix(metrics['confusion_matrix'], \n",
    "                             title=f'{name} (Tuned) Confusion Matrix',\n",
    "                             filename=f'{name.lower().replace(\" \", \"_\")}_tuned_cm.png')\n",
    "        \n",
    "        # Plot ROC curve\n",
    "        plot_roc_curve(y_test, y_prob, \n",
    "                      title=f'{name} (Tuned) ROC Curve', \n",
    "                      filename=f'{name.lower().replace(\" \", \"_\")}_tuned_roc.png')\n",
    "        \n",
    "        # Plot Precision-Recall curve\n",
    "        plot_precision_recall_curve(y_test, y_prob,\n",
    "                                  title=f'{name} (Tuned) Precision-Recall Curve',\n",
    "                                  filename=f'{name.lower().replace(\" \", \"_\")}_tuned_pr.png')\n",
    "    \n",
    "    return results\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Main execution\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Record all results\n",
    "    all_results = {}\n",
    "    \n",
    "    # Run baseline models\n",
    "    baseline_results = run_baseline_models()\n",
    "    all_results['baseline'] = baseline_results\n",
    "    \n",
    "    # Run models with resampling methods\n",
    "    resampling_results = run_resampling_models()\n",
    "    all_results['resampling'] = resampling_results\n",
    "    \n",
    "    # Run specialized algorithms for imbalanced data\n",
    "    specialized_results = run_specialized_models()\n",
    "    all_results['specialized'] = specialized_results\n",
    "    \n",
    "    # Run cost-sensitive learning\n",
    "    cost_sensitive_results = run_cost_sensitive_learning()\n",
    "    all_results['cost_sensitive'] = cost_sensitive_results\n",
    "    \n",
    "    # Perform threshold tuning\n",
    "    threshold_results = threshold_tuning()\n",
    "    all_results['threshold'] = threshold_results\n",
    "    \n",
    "    # Perform hyperparameter tuning for best models\n",
    "    tuned_results = hyperparameter_tuning()\n",
    "    all_results['tuned'] = tuned_results\n",
    "    \n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Results Comparison and Visualization\n",
    "    # -----------------------------------------------------------------------------\n",
    "    \n",
    "    # Compare all models based on F1-score\n",
    "    f1_scores = {}\n",
    "    \n",
    "    # Extract F1-scores from baseline models\n",
    "    for model_name, metrics in baseline_results.items():\n",
    "        f1_scores[f\"Baseline: {model_name}\"] = metrics['f1_score']\n",
    "    \n",
    "    # Extract F1-scores from resampling methods\n",
    "    for method_name, metrics in resampling_results.items():\n",
    "        f1_scores[f\"Resampling: {method_name}\"] = metrics['f1_score']\n",
    "    \n",
    "    # Extract F1-scores from specialized algorithms\n",
    "    for model_name, metrics in specialized_results.items():\n",
    "        f1_scores[f\"Specialized: {model_name}\"] = metrics['f1_score']\n",
    "    \n",
    "    # Extract F1-scores from cost-sensitive learning\n",
    "    for weight_name, metrics in cost_sensitive_results.items():\n",
    "        f1_scores[f\"Cost-sensitive: {weight_name}\"] = metrics['f1_score']\n",
    "    \n",
    "    # Extract F1-scores from tuned models\n",
    "    for model_name, results in tuned_results.items():\n",
    "        f1_scores[f\"Tuned: {model_name}\"] = results['metrics']['f1_score']\n",
    "    \n",
    "    # Sort models by F1-score\n",
    "    sorted_f1_scores = {k: v for k, v in sorted(f1_scores.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    # Visualize model comparison\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    plt.barh(list(sorted_f1_scores.keys()), list(sorted_f1_scores.values()))\n",
    "    plt.xlabel('F1-score')\n",
    "    plt.title('Model Comparison (F1-score)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison_f1.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\n\\n------ MODEL COMPARISON (F1-SCORE) ------\\n\")\n",
    "    for model_name, f1_score in sorted_f1_scores.items():\n",
    "        print(f\"{model_name}: {f1_score:.4f}\")\n",
    "    \n",
    "    # Find the best model overall\n",
    "    best_model_name = max(sorted_f1_scores, key=sorted_f1_scores.get)\n",
    "    print(f\"\\nBest model: {best_model_name} with F1-score: {sorted_f1_scores[best_model_name]:.4f}\")\n",
    "    \n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Feature Importance Analysis for the Best Model\n",
    "    # -----------------------------------------------------------------------------\n",
    "    \n",
    "    # For illustrative purposes, assume the best model is Random Forest\n",
    "    # This should be adjusted based on actual results\n",
    "    try:\n",
    "        # Create and train a Random Forest model with SMOTE resampling\n",
    "        pipeline = ImbPipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('resampler', SMOTE(random_state=42)),\n",
    "            ('model', RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced'))\n",
    "        ])\n",
    "        \n",
    "        # Train the model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Get feature importances\n",
    "        rf_model = pipeline.named_steps['model']\n",
    "        feature_importances = rf_model.feature_importances_\n",
    "        \n",
    "        # Create Series for feature importances\n",
    "        feature_importance_series = pd.Series(feature_importances, index=X.columns)\n",
    "        feature_importance_series = feature_importance_series.sort_values(ascending=False)\n",
    "        \n",
    "        # Plot feature importances\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        feature_importance_series.plot(kind='bar')\n",
    "        plt.title('Feature Importances from Random Forest')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('feature_importances.png')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"\\nFeature Importances:\")\n",
    "        for feature, importance in feature_importance_series.items():\n",
    "            print(f\"{feature}: {importance:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in feature importance analysis: {e}\")\n",
    "    \n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Final Model Implementation and Prediction on New Data\n",
    "    # -----------------------------------------------------------------------------\n",
    "    \n",
    "    def train_final_model():\n",
    "        \"\"\"Train the final model based on the best configuration.\"\"\"\n",
    "        print(\"\\n\\n------ FINAL MODEL ------\\n\")\n",
    "        \n",
    "        # Select the best model configuration based on results\n",
    "        # This is a placeholder - replace with the actual best model from previous steps\n",
    "        final_pipeline = ImbPipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('resampler', SMOTE(random_state=42)),\n",
    "            ('model', RandomForestClassifier(\n",
    "                n_estimators=200, \n",
    "                max_depth=10,\n",
    "                min_samples_split=5,\n",
    "                class_weight='balanced',\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Train on the full training set\n",
    "        final_pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on the test set\n",
    "        y_pred = final_pipeline.predict(X_test)\n",
    "        y_prob = final_pipeline.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Evaluate the final model\n",
    "        report, metrics = evaluate_model(y_test, y_pred, y_prob)\n",
    "        \n",
    "        print(\"\\nFinal Model Results:\")\n",
    "        print(report)\n",
    "        print(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\n",
    "        print(f\"PR AUC: {metrics['pr_auc']:.4f}\")\n",
    "        print(f\"G-mean: {metrics['g_mean']:.4f}\")\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plot_confusion_matrix(metrics['confusion_matrix'], \n",
    "                             title='Final Model Confusion Matrix',\n",
    "                             filename='final_model_cm.png')\n",
    "        \n",
    "        # Plot ROC curve\n",
    "        plot_roc_curve(y_test, y_prob, \n",
    "                      title='Final Model ROC Curve', \n",
    "                      filename='final_model_roc.png')\n",
    "        \n",
    "        # Plot Precision-Recall curve\n",
    "        plot_precision_recall_curve(y_test, y_prob,\n",
    "                                  title='Final Model Precision-Recall Curve',\n",
    "                                  filename='final_model_pr.png')\n",
    "        \n",
    "        return final_pipeline, metrics\n",
    "    \n",
    "    # Train the final model\n",
    "    final_model, final_metrics = train_final_model()\n",
    "    \n",
    "    # Function to predict on new parking lots\n",
    "    def predict_charging_potential(model, new_data):\n",
    "        \"\"\"Predict charging station potential for new parking lots.\"\"\"\n",
    "        # Preprocess new data (similar to training data)\n",
    "        # Make sure to use the same features as in training\n",
    "        if isinstance(new_data, pd.DataFrame):\n",
    "            new_data = new_data[X.columns]\n",
    "        \n",
    "        # Make predictions\n",
    "        probabilities = model.predict_proba(new_data)[:, 1]\n",
    "        predictions = model.predict(new_data)\n",
    "        \n",
    "        return predictions, probabilities\n",
    "    \n",
    "    # Example of how to use the prediction function\n",
    "    # (You can replace this with actual new data)\n",
    "    print(\"\\n\\nExample prediction on test data:\")\n",
    "    sample_indices = np.random.choice(X_test.index, 5, replace=False)\n",
    "    sample_data = X_test.loc[sample_indices]\n",
    "    \n",
    "    predictions, probabilities = predict_charging_potential(final_model, sample_data)\n",
    "    \n",
    "    results_df = pd.DataFrame({\n",
    "        'Prediction': predictions,\n",
    "        'Probability': probabilities\n",
    "    }, index=sample_indices)\n",
    "    \n",
    "    print(results_df)\n",
    "    \n",
    "    # Save the final model (optional)\n",
    "    import pickle\n",
    "    with open('evcs_prediction_model.pkl', 'wb') as file:\n",
    "        pickle.dump(final_model, file)\n",
    "    \n",
    "    print(\"\\nFinal model saved as 'evcs_prediction_model.pkl'\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Simplified API for making predictions\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def load_model(model_path='evcs_prediction_model.pkl'):\n",
    "    \"\"\"Load the trained model.\"\"\"\n",
    "    with open(model_path, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "    return model\n",
    "\n",
    "def predict_ev_charger_suitability(model, features_dict):\n",
    "    \"\"\"\n",
    "    Predict EV charger suitability for a parking lot.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : trained model\n",
    "        The trained machine learning model\n",
    "    features_dict : dict\n",
    "        Dictionary containing feature values for a parking lot\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing prediction results\n",
    "    \"\"\"\n",
    "    # Convert features dictionary to DataFrame\n",
    "    features_df = pd.DataFrame([features_dict])\n",
    "    \n",
    "    # Make sure all required features are present\n",
    "    required_features = important_features\n",
    "    for feature in required_features:\n",
    "        if feature not in features_df.columns:\n",
    "            features_df[feature] = 0  # Default value for missing features\n",
    "    \n",
    "    # Keep only the features used during training\n",
    "    features_df = features_df[required_features]\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = int(model.predict(features_df)[0])\n",
    "    probability = float(model.predict_proba(features_df)[0, 1])\n",
    "    \n",
    "    # Return results\n",
    "    return {\n",
    "        'prediction': prediction,\n",
    "        'probability': probability,\n",
    "        'suitability': 'High' if probability > 0.7 else ('Medium' if probability > 0.4 else 'Low'),\n",
    "        'explanation': generate_explanation(features_dict, probability)\n",
    "    }\n",
    "\n",
    "def generate_explanation(features, probability):\n",
    "    \"\"\"Generate a human-readable explanation for the prediction.\"\"\"\n",
    "    explanation = []\n",
    "    \n",
    "    # Add explanation based on probability\n",
    "    if probability > 0.7:\n",
    "        explanation.append(\"This parking lot has a high potential for an EV charging station.\")\n",
    "    elif probability > 0.4:\n",
    "        explanation.append(\"This parking lot has a moderate potential for an EV charging station.\")\n",
    "    else:\n",
    "        explanation.append(\"This parking lot has a low potential for an EV charging station.\")\n",
    "    \n",
    "    # Add feature-specific explanations\n",
    "    if 'distance_to_nearest_charger' in features and features['distance_to_nearest_charger'] > 1000:\n",
    "        explanation.append(\"The large distance to the nearest existing charger suggests this area may be underserved.\")\n",
    "    \n",
    "    if 'traffic' in features and features['traffic'] > 10000:\n",
    "        explanation.append(\"The high traffic volume in this area could lead to good utilization of a charging station.\")\n",
    "    \n",
    "    if 'Population' in features and features['Population'] > 6000:\n",
    "        explanation.append(\"The high population density nearby supports the need for a charging station.\")\n",
    "    \n",
    "    if 'zone_type' in features:\n",
    "        if features['zone_type'] == 'Commercial':\n",
    "            explanation.append(\"The commercial zoning is highly favorable for a charging station.\")\n",
    "        elif features['zone_type'] == 'Residential High':\n",
    "            explanation.append(\"The high-density residential zoning indicates potential for good usage.\")\n",
    "    \n",
    "    return \" \".join(explanation)\n",
    "\n",
    "# Example usage of the API\n",
    "if __name__ == \"__main__\":\n",
    "    # This would be run after the main analysis is complete\n",
    "    try:\n",
    "        # Load the saved model\n",
    "        model = load_model()\n",
    "        \n",
    "        # Example features for a new parking lot\n",
    "        example_features = {\n",
    "            'percentile_chargers_in_radius': 0.2,\n",
    "            'percentile_distance_to_nearest_charger': 0.8,\n",
    "            'distance_to_nearest_charger': 1200,\n",
    "            'percentile_cs_total': 0.3,\n",
    "            'traffic': 15000,\n",
    "            'cs_total': 0,\n",
    "            'Population': 7000,\n",
    "            'Median Income': 65000,\n",
    "            'zoning_score': 0.9,\n",
    "            'chargers_in_radius': 0,\n",
    "            'demand_score': 0.7,\n",
    "            'income_score': 0.5,\n",
    "            'population_score': 0.7\n",
    "        }\n",
    "        \n",
    "        # Make prediction\n",
    "        result = predict_ev_charger_suitability(model, example_features)\n",
    "        \n",
    "        # Print result\n",
    "        print(\"\\nPrediction API Example:\")\n",
    "        print(f\"Prediction: {'Suitable' if result['prediction'] == 1 else 'Not Suitable'}\")\n",
    "        print(f\"Probability: {result['probability']:.4f}\")\n",
    "        print(f\"Suitability: {result['suitability']}\")\n",
    "        print(f\"Explanation: {result['explanation']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in prediction API example: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02e0748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
